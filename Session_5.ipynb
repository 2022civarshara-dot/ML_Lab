{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXBC1Ojjmtx0Jte9u+aGLj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2022civarshara-dot/ML_Lab/blob/main/Session_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LkMf7DNthDIZ",
        "outputId": "be48d6b4-5526-4399-f4dc-21a9d531cb1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random dataset sample:\n",
            "   Feature_0  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  \\\n",
            "0  -1.030931   1.391626   0.547274   0.928932  -1.738880   1.250002   \n",
            "1  -2.766254   1.247870  -0.303691   1.083145   0.710836   1.968202   \n",
            "2  -0.558987   0.299849   1.527071   0.360442  -1.360209   1.100793   \n",
            "3  -1.350289  -2.046078  -0.614264   0.126459  -0.783923   5.895026   \n",
            "4  -0.275754  -0.728495   0.027727  -0.660834  -1.928161   3.544945   \n",
            "\n",
            "   Feature_6  Feature_7  Feature_8  Feature_9  Target  \n",
            "0   1.332551   1.578256   2.124722  -0.318434       0  \n",
            "1  -1.794192   2.346422   1.700778  -0.001190       1  \n",
            "2  -0.755951   1.331933   2.041105  -0.824404       0  \n",
            "3  -0.915477  -3.184768  -0.399260  -3.920960       0  \n",
            "4   1.446944  -1.111662   0.313766  -2.376528       0  \n",
            "\n",
            "===================================\n",
            " Model: Decision Tree\n",
            "===================================\n",
            "Accuracy: 0.85\n",
            "\n",
            "Confusion Matrix:\n",
            "[[134  28]\n",
            " [ 17 121]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.83      0.86       162\n",
            "           1       0.81      0.88      0.84       138\n",
            "\n",
            "    accuracy                           0.85       300\n",
            "   macro avg       0.85      0.85      0.85       300\n",
            "weighted avg       0.85      0.85      0.85       300\n",
            "\n",
            "\n",
            "===================================\n",
            " Model: Bagging\n",
            "===================================\n",
            "Accuracy: 0.8733333333333333\n",
            "\n",
            "Confusion Matrix:\n",
            "[[137  25]\n",
            " [ 13 125]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.85      0.88       162\n",
            "           1       0.83      0.91      0.87       138\n",
            "\n",
            "    accuracy                           0.87       300\n",
            "   macro avg       0.87      0.88      0.87       300\n",
            "weighted avg       0.88      0.87      0.87       300\n",
            "\n",
            "\n",
            "===================================\n",
            " Model: Boosting (AdaBoost)\n",
            "===================================\n",
            "Accuracy: 0.8\n",
            "\n",
            "Confusion Matrix:\n",
            "[[113  49]\n",
            " [ 11 127]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.70      0.79       162\n",
            "           1       0.72      0.92      0.81       138\n",
            "\n",
            "    accuracy                           0.80       300\n",
            "   macro avg       0.82      0.81      0.80       300\n",
            "weighted avg       0.82      0.80      0.80       300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Bagging and Boosting\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. Generate a random supervised classification dataset\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=10,\n",
        "    n_informative=6,\n",
        "    n_redundant=2,\n",
        "    n_classes=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "df = pd.DataFrame(X, columns=[f\"Feature_{i}\" for i in range(X.shape[1])])\n",
        "df[\"Target\"] = y\n",
        "\n",
        "print(\"Random dataset sample:\")\n",
        "print(df.head())\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. Train-test split\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop(columns=[\"Target\"]),\n",
        "    df[\"Target\"],\n",
        "    test_size=0.30,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. Scaling\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 4. Base Decision Tree\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(X_train, y_train)\n",
        "dt_pred = dt_model.predict(X_test)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 5. Bagging (FIXED for sklearn >=1.4)\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "bag_model = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),   # <-- FIXED\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bag_model.fit(X_train, y_train)\n",
        "bag_pred = bag_model.predict(X_test)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 6. Boosting (AdaBoost FIXED)\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "boost_model = AdaBoostClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=1),  # <-- FIXED\n",
        "    n_estimators=50,\n",
        "    learning_rate=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "boost_model.fit(X_train, y_train)\n",
        "boost_pred = boost_model.predict(X_test)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 7. Evaluation Function\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "def evaluate(model_name, y_true, y_pred):\n",
        "    print(\"\\n===================================\")\n",
        "    print(f\" Model: {model_name}\")\n",
        "    print(\"===================================\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 8. Print Model Performances\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "evaluate(\"Decision Tree\", y_test, dt_pred)\n",
        "evaluate(\"Bagging\", y_test, bag_pred)\n",
        "evaluate(\"Boosting (AdaBoost)\", y_test, boost_pred)"
      ]
    }
  ]
}