{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvcRPAmREqUr+0RiRLx3Nb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2022civarshara-dot/ML_Lab/blob/main/ML_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkUo_1oXZltQ",
        "outputId": "870791e5-8c6c-4a70-a7d4-4f2ed2270859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final General Hypothesis:\n",
            "\n",
            "Final Specific Hypothesis:\n",
            "['?']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def candidate_elimination(examples):\n",
        "    \"\"\"\n",
        "    Implements the Candidate Elimination algorithm.\n",
        "\n",
        "    Args:\n",
        "        examples: A list of tuples, where each tuple represents an example.\n",
        "                  The last element of each tuple is the class label (True for positive, False for negative).\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing the final general hypothesis and the final specific hypothesis.\n",
        "    \"\"\"\n",
        "    num_attributes = len(examples[0]) - 1\n",
        "    specific_hypothesis = ['0'] * num_attributes\n",
        "    general_hypothesis = [['?' for _ in range(num_attributes)]]\n",
        "\n",
        "    for example in examples:\n",
        "        attributes = example[:-1]\n",
        "        label = example[-1]\n",
        "\n",
        "        if label:  # Positive example\n",
        "            # Update specific hypothesis\n",
        "            for i in range(num_attributes):\n",
        "                if specific_hypothesis[i] == '0':\n",
        "                    specific_hypothesis[i] = attributes[i]\n",
        "                elif specific_hypothesis[i] != attributes[i]:\n",
        "                    specific_hypothesis[i] = '?'\n",
        "\n",
        "            # Remove inconsistent hypotheses from general hypothesis\n",
        "            general_hypothesis = [h for h in general_hypothesis if all(h[i] == '?' or h[i] == attributes[i] for i in range(num_attributes))]\n",
        "\n",
        "        else:  # Negative example\n",
        "            # Refine general hypothesis\n",
        "            new_general_hypothesis = []\n",
        "            for h in general_hypothesis:\n",
        "                if all(h[i] == '?' or h[i] == attributes[i] for i in range(num_attributes)):\n",
        "                    for i in range(num_attributes):\n",
        "                        if h[i] == '?':\n",
        "                            for value in set([ex[:-1][i] for ex in examples]):\n",
        "                                if value != attributes[i]:\n",
        "                                    new_h = list(h)\n",
        "                                    new_h[i] = value\n",
        "                                    if all(new_h[j] == '?' or new_h[j] == specific_hypothesis[j] for j in range(num_attributes)):\n",
        "                                        new_general_hypothesis.append(new_h)\n",
        "                else:\n",
        "                    new_general_hypothesis.append(h)\n",
        "            general_hypothesis = new_general_hypothesis\n",
        "\n",
        "    return general_hypothesis, specific_hypothesis\n",
        "\n",
        "# Example usage:\n",
        "examples = [\n",
        "    (('Sunny', 'Warm', 'Normal', 'Strong', 'Warm', 'Same'), True),\n",
        "    (('Sunny', 'Warm', 'High', 'Strong', 'Warm', 'Same'), True),\n",
        "    (('Rainy', 'Cold', 'High', 'Strong', 'Warm', 'Change'), False),\n",
        "    (('Sunny', 'Warm', 'High', 'Strong', 'Cool', 'Change'), True)\n",
        "]\n",
        "\n",
        "general, specific = candidate_elimination(examples)\n",
        "\n",
        "print(\"Final General Hypothesis:\")\n",
        "for h in general:\n",
        "    print(h)\n",
        "print(\"\\nFinal Specific Hypothesis:\")\n",
        "print(specific)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def candidate_elimination(examples):\n",
        "    \"\"\"\n",
        "    Implements the Candidate Elimination algorithm.\n",
        "\n",
        "    Args:\n",
        "        examples: A list of tuples, where each tuple represents an example.\n",
        "                  The last element of each tuple is the class label (True for positive, False for negative).\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing the final general hypothesis and the final specific hypothesis.\n",
        "    \"\"\"\n",
        "    num_attributes = len(examples[0][0])  # Number of attributes\n",
        "    specific_hypothesis = ['0'] * num_attributes\n",
        "    general_hypothesis = [['?' for _ in range(num_attributes)]]\n",
        "\n",
        "    # Get the set of all possible attribute values from the training examples\n",
        "    all_values = [set() for _ in range(num_attributes)]\n",
        "    for example in examples:\n",
        "        attributes = example[0]\n",
        "        for i, val in enumerate(attributes):\n",
        "            all_values[i].add(val)\n",
        "\n",
        "    for example in examples:\n",
        "        attributes = example[0]\n",
        "        label = example[1]\n",
        "\n",
        "        if label:  # Positive example\n",
        "            # Update specific hypothesis (S)\n",
        "            for i in range(num_attributes):\n",
        "                if specific_hypothesis[i] == '0':\n",
        "                    specific_hypothesis[i] = attributes[i]\n",
        "                elif specific_hypothesis[i] != attributes[i]:\n",
        "                    specific_hypothesis[i] = '?'\n",
        "\n",
        "            # Remove inconsistent hypotheses from general hypothesis (G)\n",
        "            new_general_hypothesis = []\n",
        "            for h in general_hypothesis:\n",
        "                # Check if current hypothesis matches the example\n",
        "                if all(h[i] == '?' or h[i] == attributes[i] for i in range(num_attributes)):\n",
        "                    new_general_hypothesis.append(h)\n",
        "            general_hypothesis = new_general_hypothesis\n",
        "\n",
        "        else:  # Negative example\n",
        "            # Refine general hypothesis (G) based on negative example\n",
        "            new_general_hypothesis = []\n",
        "            for h in general_hypothesis:\n",
        "                # If the hypothesis is inconsistent with the negative example, we keep it\n",
        "                if any(h[i] != '?' and h[i] != attributes[i] for i in range(num_attributes)):\n",
        "                    new_general_hypothesis.append(h)\n",
        "                else:\n",
        "                    # Generate new general hypotheses by specializing existing ones\n",
        "                    for i in range(num_attributes):\n",
        "                        if h[i] == '?':\n",
        "                            for value in all_values[i]:\n",
        "                                if value != attributes[i]:\n",
        "                                    new_h = list(h)\n",
        "                                    new_h[i] = value\n",
        "                                    if all(new_h[j] == '?' or new_h[j] == specific_hypothesis[j] for j in range(num_attributes)):\n",
        "                                        new_general_hypothesis.append(new_h)\n",
        "            general_hypothesis = new_general_hypothesis\n",
        "\n",
        "    return general_hypothesis, specific_hypothesis\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "examples = [\n",
        "    (('Sunny', 'Warm', 'Normal', 'Strong', 'Warm', 'Same'), True),\n",
        "    (('Sunny', 'Warm', 'High', 'Strong', 'Warm', 'Same'), True),\n",
        "    (('Rainy', 'Cold', 'High', 'Strong', 'Warm', 'Change'), False),\n",
        "    (('Sunny', 'Warm', 'High', 'Strong', 'Cool', 'Change'), True)\n",
        "]\n",
        "\n",
        "general, specific = candidate_elimination(examples)\n",
        "\n",
        "print(\"Final General Hypothesis:\")\n",
        "for h in general:\n",
        "    print(h)\n",
        "print(\"\\nFinal Specific Hypothesis:\")\n",
        "print(specific)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQmChzZyZpbu",
        "outputId": "0f4837c0-0f11-4ba6-a0a9-5cb92e107756"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final General Hypothesis:\n",
            "['Sunny', '?', '?', '?', '?', '?']\n",
            "['?', 'Warm', '?', '?', '?', '?']\n",
            "\n",
            "Final Specific Hypothesis:\n",
            "['Sunny', 'Warm', '?', 'Strong', '?', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lab 2\n",
        "import numpy as np\n",
        "\n",
        "def candidate_elimination(examples):\n",
        "    \"\"\"\n",
        "    Implements the Candidate Elimination algorithm.\n",
        "\n",
        "    Args:\n",
        "        examples: A list of tuples, where each tuple represents an example.\n",
        "                  The last element of each tuple is the class label (True for positive, False for negative).\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing the final general hypothesis and the final specific hypothesis.\n",
        "    \"\"\"\n",
        "    num_attributes = len(examples[0][0])  # Number of attributes\n",
        "    specific_hypothesis = ['0'] * num_attributes\n",
        "    general_hypothesis = [['?' for _ in range(num_attributes)]]\n",
        "\n",
        "    # Get the set of all possible attribute values from the training examples\n",
        "    all_values = [set() for _ in range(num_attributes)]\n",
        "    for example in examples:\n",
        "        attributes = example[0]\n",
        "        for i, val in enumerate(attributes):\n",
        "            all_values[i].add(val)\n",
        "\n",
        "    for example in examples:\n",
        "        attributes = example[0]\n",
        "        label = example[1]\n",
        "\n",
        "        if label:  # Positive example\n",
        "            # Update specific hypothesis (S)\n",
        "            for i in range(num_attributes):\n",
        "                if specific_hypothesis[i] == '0':\n",
        "                    specific_hypothesis[i] = attributes[i]\n",
        "                elif specific_hypothesis[i] != attributes[i]:\n",
        "                    specific_hypothesis[i] = '?'\n",
        "\n",
        "            # Remove inconsistent hypotheses from general hypothesis (G)\n",
        "            new_general_hypothesis = []\n",
        "            for h in general_hypothesis:\n",
        "                # Check if current hypothesis matches the example\n",
        "                if all(h[i] == '?' or h[i] == attributes[i] for i in range(num_attributes)):\n",
        "                    new_general_hypothesis.append(h)\n",
        "            general_hypothesis = new_general_hypothesis\n",
        "\n",
        "        else:  # Negative example\n",
        "            # Refine general hypothesis (G) based on negative example\n",
        "            new_general_hypothesis = []\n",
        "            for h in general_hypothesis:\n",
        "                # If the hypothesis is inconsistent with the negative example, we keep it\n",
        "                if any(h[i] != '?' and h[i] != attributes[i] for i in range(num_attributes)):\n",
        "                    new_general_hypothesis.append(h)\n",
        "                else:\n",
        "                    # Generate new general hypotheses by specializing existing ones\n",
        "                    for i in range(num_attributes):\n",
        "                        if h[i] == '?':\n",
        "                            for value in all_values[i]:\n",
        "                                if value != attributes[i]:\n",
        "                                    new_h = list(h)\n",
        "                                    new_h[i] = value\n",
        "                                    if all(new_h[j] == '?' or new_h[j] == specific_hypothesis[j] for j in range(num_attributes)):\n",
        "                                        new_general_hypothesis.append(new_h)\n",
        "            general_hypothesis = new_general_hypothesis\n",
        "\n",
        "    return general_hypothesis, specific_hypothesis\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "examples = [\n",
        "    (('Senior', 'Low', 'No', 'Fair', 'Unemployed', 'No'), True),\n",
        "    (('Young', 'High', 'No', 'Fair', 'Employed', 'Yes'), False),\n",
        "    (('Young', 'Medium', 'Yes', 'Excellent', 'Employed', 'No'), False),\n",
        "    (('Middle', 'High', 'Yes', 'Excellent', 'Employed', 'Yes'), True),\n",
        "    (('Young', 'Low', 'Yes', 'Fair', 'Unemployed', 'No'), True),\n",
        "    (('Senior', 'Medium', 'No', 'Fair', 'Employed', 'Yes'), True)\n",
        "]\n",
        "\n",
        "general, specific = candidate_elimination(examples)\n",
        "\n",
        "print(\"Final General Hypothesis:\")\n",
        "for h in general:\n",
        "    print(h)\n",
        "print(\"\\nFinal Specific Hypothesis:\")\n",
        "print(specific)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74awdvFpZwKd",
        "outputId": "f2ae9ead-8b09-4324-82ea-888c9af60720"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final General Hypothesis:\n",
            "\n",
            "Final Specific Hypothesis:\n",
            "['?', '?', '?', '?', '?', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install orange3 pandas scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaFerBaoaMiW",
        "outputId": "1d1a8d4f-7194-4091-9eba-e752fa3b5376"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting orange3\n",
            "  Downloading orange3-3.39.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting AnyQt>=0.2.0 (from orange3)\n",
            "  Downloading anyqt-0.2.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting baycomp>=1.0.2 (from orange3)\n",
            "  Downloading baycomp-1.0.3.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: bottleneck>=1.3.4 in /usr/local/lib/python3.12/dist-packages (from orange3) (1.4.2)\n",
            "Requirement already satisfied: chardet>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from orange3) (5.2.0)\n",
            "Requirement already satisfied: httpx>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from orange3) (0.28.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from orange3) (1.5.2)\n",
            "Requirement already satisfied: keyring in /usr/local/lib/python3.12/dist-packages (from orange3) (25.7.0)\n",
            "Collecting keyrings.alt (from orange3)\n",
            "  Downloading keyrings.alt-5.0.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: matplotlib>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from orange3) (3.10.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from orange3) (3.5)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from orange3) (2.0.2)\n",
            "Collecting openTSNE!=0.7.0,>=0.6.2 (from orange3)\n",
            "  Downloading opentsne-1.0.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: openpyxl>=3.1.3 in /usr/local/lib/python3.12/dist-packages (from orange3) (3.1.5)\n",
            "Collecting orange-canvas-core<0.3a,>=0.2.5 (from orange3)\n",
            "  Downloading orange_canvas_core-0.2.6-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting orange-widget-base>=4.25.0 (from orange3)\n",
            "  Downloading orange_widget_base-4.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from orange3) (25.0)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.12/dist-packages (from orange3) (24.1.2)\n",
            "Requirement already satisfied: pygments>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from orange3) (2.19.2)\n",
            "Collecting pyqtgraph>=0.13.1 (from orange3)\n",
            "  Downloading pyqtgraph-0.14.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: python-louvain>=0.13 in /usr/local/lib/python3.12/dist-packages (from orange3) (0.16)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from orange3) (6.0.3)\n",
            "Collecting qtconsole>=4.7.2 (from orange3)\n",
            "  Downloading qtconsole-5.7.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from orange3) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.12/dist-packages (from orange3) (1.16.3)\n",
            "Collecting serverfiles (from orange3)\n",
            "  Downloading serverfiles-0.3.1.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting xgboost<2.1,>=1.7.4 (from orange3)\n",
            "  Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from orange3) (2.0.2)\n",
            "Collecting xlsxwriter (from orange3)\n",
            "  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.0->orange3) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.0->orange3) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.0->orange3) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.0->orange3) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.21.0->orange3) (0.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.0->orange3) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.0->orange3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.0->orange3) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.0->orange3) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.0->orange3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.0->orange3) (3.2.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl>=3.1.3->orange3) (2.0.0)\n",
            "Requirement already satisfied: docutils in /usr/local/lib/python3.12/dist-packages (from orange-canvas-core<0.3a,>=0.2.5->orange3) (0.21.2)\n",
            "Collecting commonmark>=0.8.1 (from orange-canvas-core<0.3a,>=0.2.5->orange3)\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting requests-cache (from orange-canvas-core<0.3a,>=0.2.5->orange3)\n",
            "  Downloading requests_cache-1.2.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting dictdiffer (from orange-canvas-core<0.3a,>=0.2.5->orange3)\n",
            "  Downloading dictdiffer-0.9.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting qasync>=0.10.0 (from orange-canvas-core<0.3a,>=0.2.5->orange3)\n",
            "  Downloading qasync-0.28.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from orange-canvas-core<0.3a,>=0.2.5->orange3) (4.15.0)\n",
            "Collecting truststore (from orange-canvas-core<0.3a,>=0.2.5->orange3)\n",
            "  Downloading truststore-0.10.4-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting colorama (from pyqtgraph>=0.13.1->orange3)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: traitlets!=5.2.1,!=5.2.2 in /usr/local/lib/python3.12/dist-packages (from qtconsole>=4.7.2->orange3) (5.7.1)\n",
            "Requirement already satisfied: jupyter_core in /usr/local/lib/python3.12/dist-packages (from qtconsole>=4.7.2->orange3) (5.9.1)\n",
            "Requirement already satisfied: jupyter_client>=4.1 in /usr/local/lib/python3.12/dist-packages (from qtconsole>=4.7.2->orange3) (7.4.9)\n",
            "Requirement already satisfied: ipykernel>=4.1 in /usr/local/lib/python3.12/dist-packages (from qtconsole>=4.7.2->orange3) (6.17.1)\n",
            "Collecting ipython_pygments_lexers (from qtconsole>=4.7.2->orange3)\n",
            "  Downloading ipython_pygments_lexers-1.1.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting qtpy>=2.4.0 (from qtconsole>=4.7.2->orange3)\n",
            "  Downloading QtPy-2.4.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: SecretStorage>=3.2 in /usr/local/lib/python3.12/dist-packages (from keyring->orange3) (3.4.1)\n",
            "Requirement already satisfied: jeepney>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from keyring->orange3) (0.9.0)\n",
            "Requirement already satisfied: jaraco.classes in /usr/local/lib/python3.12/dist-packages (from keyring->orange3) (3.4.0)\n",
            "Requirement already satisfied: jaraco.functools in /usr/local/lib/python3.12/dist-packages (from keyring->orange3) (4.3.0)\n",
            "Requirement already satisfied: jaraco.context in /usr/local/lib/python3.12/dist-packages (from keyring->orange3) (6.0.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->orange3) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->orange3) (2.5.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.1->qtconsole>=4.7.2->orange3) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.1->qtconsole>=4.7.2->orange3) (7.34.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.1->qtconsole>=4.7.2->orange3) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.1->qtconsole>=4.7.2->orange3) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.1->qtconsole>=4.7.2->orange3) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.1->qtconsole>=4.7.2->orange3) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.1->qtconsole>=4.7.2->orange3) (6.5.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter_client>=4.1->qtconsole>=4.7.2->orange3) (0.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter_core->qtconsole>=4.7.2->orange3) (4.5.0)\n",
            "Requirement already satisfied: cryptography>=2.0 in /usr/local/lib/python3.12/dist-packages (from SecretStorage>=3.2->keyring->orange3) (43.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.21.0->orange3) (1.3.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from jaraco.classes->keyring->orange3) (10.8.0)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.12/dist-packages (from requests-cache->orange-canvas-core<0.3a,>=0.2.5->orange3) (25.4.0)\n",
            "Collecting cattrs>=22.2 (from requests-cache->orange-canvas-core<0.3a,>=0.2.5->orange3)\n",
            "  Downloading cattrs-25.3.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting url-normalize>=1.4 (from requests-cache->orange-canvas-core<0.3a,>=0.2.5->orange3)\n",
            "  Downloading url_normalize-2.2.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring->orange3) (2.0.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel>=4.1->qtconsole>=4.7.2->orange3) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel>=4.1->qtconsole>=4.7.2->orange3)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel>=4.1->qtconsole>=4.7.2->orange3) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel>=4.1->qtconsole>=4.7.2->orange3) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel>=4.1->qtconsole>=4.7.2->orange3) (3.0.52)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel>=4.1->qtconsole>=4.7.2->orange3) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel>=4.1->qtconsole>=4.7.2->orange3) (4.9.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring->orange3) (2.23)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=4.1->qtconsole>=4.7.2->orange3) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=4.1->qtconsole>=4.7.2->orange3) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=4.1->qtconsole>=4.7.2->orange3) (0.2.14)\n",
            "Downloading orange3-3.39.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anyqt-0.2.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentsne-1.0.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m112.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orange_canvas_core-0.2.6-py3-none-any.whl (535 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m535.3/535.3 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orange_widget_base-4.26.0-py3-none-any.whl (270 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.3/270.3 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyqtgraph-0.14.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qtconsole-5.7.0-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.7/125.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keyrings.alt-5.0.2-py3-none-any.whl (17 kB)\n",
            "Downloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qasync-0.28.0-py3-none-any.whl (16 kB)\n",
            "Downloading QtPy-2.4.3-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.0/95.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading dictdiffer-0.9.0-py2.py3-none-any.whl (16 kB)\n",
            "Downloading ipython_pygments_lexers-1.1.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading requests_cache-1.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading truststore-0.10.4-py3-none-any.whl (18 kB)\n",
            "Downloading cattrs-25.3.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.7/70.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading url_normalize-2.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: baycomp, serverfiles\n",
            "  Building wheel for baycomp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for baycomp: filename=baycomp-1.0.3-py3-none-any.whl size=18027 sha256=2b413b955fa9f4b2fa6e0a6e4f4e51da0c2de72f09dfaf40914b5024491a3ee3\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/39/6a/f87e05ad75b9d87f4eb262a897ec2fe3aab09449d13e3c3b2c\n",
            "  Building wheel for serverfiles (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for serverfiles: filename=serverfiles-0.3.1-py3-none-any.whl size=6923 sha256=ae0db8bbbf39d05f3ed116d176353c609605bdeea84cbc7b71d72de120fb4569\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/b0/a2/a1adac874bb0c4a781f1d9d919d5435c1ba021570c5b0f470c\n",
            "Successfully built baycomp serverfiles\n",
            "Installing collected packages: dictdiffer, commonmark, xlsxwriter, url-normalize, truststore, qtpy, qasync, jedi, ipython_pygments_lexers, colorama, cattrs, AnyQt, xgboost, serverfiles, requests-cache, pyqtgraph, keyrings.alt, orange-canvas-core, openTSNE, baycomp, qtconsole, orange-widget-base, orange3\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 3.1.2\n",
            "    Uninstalling xgboost-3.1.2:\n",
            "      Successfully uninstalled xgboost-3.1.2\n",
            "Successfully installed AnyQt-0.2.1 baycomp-1.0.3 cattrs-25.3.0 colorama-0.4.6 commonmark-0.9.1 dictdiffer-0.9.0 ipython_pygments_lexers-1.1.1 jedi-0.19.2 keyrings.alt-5.0.2 openTSNE-1.0.4 orange-canvas-core-0.2.6 orange-widget-base-4.26.0 orange3-3.39.0 pyqtgraph-0.14.0 qasync-0.28.0 qtconsole-5.7.0 qtpy-2.4.3 requests-cache-1.2.1 serverfiles-0.3.1 truststore-0.10.4 url-normalize-2.2.1 xgboost-2.0.3 xlsxwriter-3.2.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lab 3\n",
        "import Orange\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset (Iris dataset)\n",
        "data = Orange.data.Table(\"iris\")\n",
        "\n",
        "# --- Example-based learning using CN2 (propositional rules) ---\n",
        "print(\"=== CN2 Rule Learning ===\")\n",
        "cn2_learner = Orange.classification.rules.CN2Learner()\n",
        "cn2_classifier = cn2_learner(data)\n",
        "\n",
        "for rule in cn2_classifier.rule_list:\n",
        "    print(rule)\n",
        "\n",
        "# --- FOIL-style Rule Learning (Simulated) ---\n",
        "print(\"\\n=== FOIL-style Rule Learning (Simulated) ===\")\n",
        "\n",
        "def foil_like_rule_learning(data):\n",
        "    \"\"\"\n",
        "    A simplified FOIL-style rule generator.\n",
        "    Handles both discrete and continuous attributes.\n",
        "    \"\"\"\n",
        "    rules = []\n",
        "    domain = data.domain\n",
        "    class_var = domain.class_var\n",
        "\n",
        "    for attr in domain.attributes:\n",
        "        if attr.is_discrete:\n",
        "            # For categorical attributes\n",
        "            for value in attr.values:\n",
        "                for class_value in class_var.values:\n",
        "                    rules.append(f\"IF {attr.name} = {value} THEN {class_var.name} = {class_value}\")\n",
        "        else:\n",
        "            # For continuous attributes, compute mean using NumPy\n",
        "            column = np.array([d[attr] for d in data if not np.isnan(d[attr])], dtype=float)\n",
        "            if len(column) == 0:\n",
        "                continue\n",
        "            mean_val = np.mean(column)\n",
        "\n",
        "            for class_value in class_var.values:\n",
        "                rules.append(f\"IF {attr.name} > {mean_val:.2f} THEN {class_var.name} = {class_value}\")\n",
        "                rules.append(f\"IF {attr.name} <= {mean_val:.2f} THEN {class_var.name} = {class_value}\")\n",
        "\n",
        "    return rules\n",
        "\n",
        "foil_rules = foil_like_rule_learning(data)\n",
        "\n",
        "# Print some example FOIL-style rules\n",
        "for i, rule in enumerate(foil_rules[:10], start=1):\n",
        "    print(f\"{i}. {rule}\")\n",
        "\n",
        "print(\"\\nNote: This simulates FOIL-style rule induction using continuous thresholds, \"\n",
        "      \"since Orange’s Iris dataset features are numeric.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGR1Hmw1Zy-G",
        "outputId": "5b54cef5-d780-4b04-9364-1bf1131a967e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CN2 Rule Learning ===\n",
            "IF petal length<=3.0 AND sepal width>=2.9 THEN iris=Iris-setosa \n",
            "IF petal width>=1.8 AND sepal length>=6.0 THEN iris=Iris-virginica \n",
            "IF sepal length>=4.9 AND sepal width>=3.1 THEN iris=Iris-versicolor \n",
            "IF petal length<=4.9 AND petal width>=1.7 THEN iris=Iris-virginica \n",
            "IF petal width>=1.8 THEN iris=Iris-virginica \n",
            "IF petal length<=5.0 AND sepal width>=2.4 THEN iris=Iris-versicolor \n",
            "IF sepal width>=2.8 THEN iris=Iris-virginica \n",
            "IF petal width<=1.0 AND sepal length>=5.0 THEN iris=Iris-versicolor \n",
            "IF sepal width>=2.7 THEN iris=Iris-versicolor \n",
            "IF sepal width>=2.6 THEN iris=Iris-virginica \n",
            "IF sepal length>=5.5 AND sepal length>=6.2 THEN iris=Iris-versicolor \n",
            "IF sepal length<=5.5 AND petal length>=4.0 THEN iris=Iris-versicolor \n",
            "IF sepal length>=6.0 THEN iris=Iris-virginica \n",
            "IF sepal length<=4.5 THEN iris=Iris-setosa \n",
            "IF TRUE THEN iris=Iris-versicolor \n",
            "\n",
            "=== FOIL-style Rule Learning (Simulated) ===\n",
            "1. IF sepal length > 5.84 THEN iris = Iris-setosa\n",
            "2. IF sepal length <= 5.84 THEN iris = Iris-setosa\n",
            "3. IF sepal length > 5.84 THEN iris = Iris-versicolor\n",
            "4. IF sepal length <= 5.84 THEN iris = Iris-versicolor\n",
            "5. IF sepal length > 5.84 THEN iris = Iris-virginica\n",
            "6. IF sepal length <= 5.84 THEN iris = Iris-virginica\n",
            "7. IF sepal width > 3.05 THEN iris = Iris-setosa\n",
            "8. IF sepal width <= 3.05 THEN iris = Iris-setosa\n",
            "9. IF sepal width > 3.05 THEN iris = Iris-versicolor\n",
            "10. IF sepal width <= 3.05 THEN iris = Iris-versicolor\n",
            "\n",
            "Note: This simulates FOIL-style rule induction using continuous thresholds, since Orange’s Iris dataset features are numeric.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris(as_frame=True)\n",
        "data = iris.frame\n",
        "\n",
        "# Display first few rows\n",
        "print(data.head())\n",
        "\n",
        "# Split into train/test\n",
        "train_data, test_data = train_test_split(data, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_caYqEepaccH",
        "outputId": "ba9c8b96-be6f-4639-a0a5-528d068be2b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   target  \n",
            "0       0  \n",
            "1       0  \n",
            "2       0  \n",
            "3       0  \n",
            "4       0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Orange.data import Table, Domain, ContinuousVariable, DiscreteVariable\n",
        "\n",
        "# Define the domain (feature types)\n",
        "features = [ContinuousVariable(var) for var in iris.feature_names]\n",
        "target = DiscreteVariable('target', values=list(iris.target_names))\n",
        "domain = Domain(features, target)\n",
        "\n",
        "# Convert to Orange Table\n",
        "orange_data = Table.from_list(domain, data.values)"
      ],
      "metadata": {
        "id": "w0vttPHialkl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Orange.classification.rules import CN2Learner\n",
        "\n",
        "# Initialize learner\n",
        "learner = CN2Learner()\n",
        "\n",
        "# Train\n",
        "classifier = learner(orange_data)\n",
        "\n",
        "# Print the induced rules\n",
        "for rule in classifier.rule_list:\n",
        "    print(rule)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su_x8LqSany-",
        "outputId": "b5e3ee6d-4064-41da-dabc-e24d445f3731"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IF petal length (cm)<=3.0 AND sepal width (cm)>=2.9 THEN target=setosa \n",
            "IF petal width (cm)>=1.8 AND sepal length (cm)>=6.0 THEN target=virginica \n",
            "IF sepal length (cm)>=4.9 AND sepal width (cm)>=3.1 THEN target=versicolor \n",
            "IF petal length (cm)<=4.9 AND petal width (cm)>=1.7 THEN target=virginica \n",
            "IF petal width (cm)>=1.8 THEN target=virginica \n",
            "IF petal length (cm)<=5.0 AND sepal width (cm)>=2.4 THEN target=versicolor \n",
            "IF sepal width (cm)>=2.8 THEN target=virginica \n",
            "IF petal width (cm)<=1.0 AND sepal length (cm)>=5.0 THEN target=versicolor \n",
            "IF sepal width (cm)>=2.7 THEN target=versicolor \n",
            "IF sepal width (cm)>=2.6 THEN target=virginica \n",
            "IF sepal length (cm)>=5.5 AND sepal length (cm)>=6.2 THEN target=versicolor \n",
            "IF sepal length (cm)<=5.5 AND petal length (cm)>=4.0 THEN target=versicolor \n",
            "IF sepal length (cm)>=6.0 THEN target=virginica \n",
            "IF sepal length (cm)<=4.5 THEN target=setosa \n",
            "IF TRUE THEN target=setosa \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Orange.evaluation import TestOnTestData, CA\n",
        "\n",
        "# Convert train/test to Orange format\n",
        "train_orange = Table.from_list(domain, train_data.values)\n",
        "test_orange = Table.from_list(domain, test_data.values)\n",
        "\n",
        "# Evaluate accuracy\n",
        "results = TestOnTestData(train_orange, test_orange, [learner])\n",
        "print(\"Classification Accuracy:\", CA(results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaTf0XsXasSN",
        "outputId": "f83bcf3d-57ce-4496-be09-bed4498a0fd0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Accuracy: [1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def foil_gain(p0, n0, p1, n1):\n",
        "    # FOIL-Gain formula\n",
        "    if p1 == 0:\n",
        "        return 0\n",
        "    return p1 * (math.log2(p1 / (p1 + n1)) - math.log2(p0 / (p0 + n0)))\n",
        "\n",
        "def foil_algorithm(examples, target_attr):\n",
        "    \"\"\"\n",
        "    examples: list of dicts, each with features and target\n",
        "    target_attr: string name of target attribute\n",
        "    \"\"\"\n",
        "    rules = []\n",
        "    positives = [ex for ex in examples if ex[target_attr] == 1]\n",
        "    negatives = [ex for ex in examples if ex[target_attr] == 0]\n",
        "\n",
        "    while positives:\n",
        "        current_rule = []\n",
        "        covered_pos = positives\n",
        "        covered_neg = negatives\n",
        "\n",
        "        while covered_neg:\n",
        "            best_gain = 0\n",
        "            best_literal = None\n",
        "\n",
        "            # Try all possible feature-value pairs\n",
        "            for attr in examples[0].keys():\n",
        "                if attr == target_attr:\n",
        "                    continue\n",
        "\n",
        "                for val in set(ex[attr] for ex in examples):\n",
        "                    p1 = len([ex for ex in covered_pos if ex[attr] == val])\n",
        "                    n1 = len([ex for ex in covered_neg if ex[attr] == val])\n",
        "                    gain = foil_gain(len(covered_pos), len(covered_neg), p1, n1)\n",
        "                    if gain > best_gain:\n",
        "                        best_gain, best_literal = gain, (attr, val)\n",
        "\n",
        "            if not best_literal:\n",
        "                break\n",
        "\n",
        "            attr, val = best_literal\n",
        "            current_rule.append((attr, val))\n",
        "\n",
        "            # Keep only examples matching this literal\n",
        "            covered_pos = [ex for ex in covered_pos if ex[attr] == val]\n",
        "            covered_neg = [ex for ex in covered_neg if ex[attr] == val]\n",
        "\n",
        "        # Save the rule\n",
        "        rules.append((current_rule, 1))\n",
        "        positives = [ex for ex in positives if ex not in covered_pos]\n",
        "\n",
        "    return rules"
      ],
      "metadata": {
        "id": "FfUC2eAqatgm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. Generate a random supervised classification dataset\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=10,\n",
        "    n_informative=6,\n",
        "    n_redundant=2,\n",
        "    n_classes=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "df = pd.DataFrame(X, columns=[f\"Feature_{i}\" for i in range(X.shape[1])])\n",
        "df[\"Target\"] = y\n",
        "\n",
        "print(\"Random dataset sample:\")\n",
        "print(df.head())\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. Train-test split\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop(columns=[\"Target\"]),\n",
        "    df[\"Target\"],\n",
        "    test_size=0.30,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. Scaling\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 4. Base Decision Tree\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(X_train, y_train)\n",
        "dt_pred = dt_model.predict(X_test)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 5. Bagging (FIXED for sklearn >=1.4)\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "bag_model = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),   # <-- FIXED\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bag_model.fit(X_train, y_train)\n",
        "bag_pred = bag_model.predict(X_test)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 6. Boosting (AdaBoost FIXED)\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "boost_model = AdaBoostClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=1),  # <-- FIXED\n",
        "    n_estimators=50,\n",
        "    learning_rate=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "boost_model.fit(X_train, y_train)\n",
        "boost_pred = boost_model.predict(X_test)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 7. Evaluation Function\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "def evaluate(model_name, y_true, y_pred):\n",
        "    print(\"\\n===================================\")\n",
        "    print(f\" Model: {model_name}\")\n",
        "    print(\"===================================\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 8. Print Model Performances\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "evaluate(\"Decision Tree\", y_test, dt_pred)\n",
        "evaluate(\"Bagging\", y_test, bag_pred)\n",
        "evaluate(\"Boosting (AdaBoost)\", y_test, boost_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLmaFNfVbFMn",
        "outputId": "ddb27619-ca73-4a95-da35-96fe83387e6b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random dataset sample:\n",
            "   Feature_0  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  \\\n",
            "0  -1.030931   1.391626   0.547274   0.928932  -1.738880   1.250002   \n",
            "1  -2.766254   1.247870  -0.303691   1.083145   0.710836   1.968202   \n",
            "2  -0.558987   0.299849   1.527071   0.360442  -1.360209   1.100793   \n",
            "3  -1.350289  -2.046078  -0.614264   0.126459  -0.783923   5.895026   \n",
            "4  -0.275754  -0.728495   0.027727  -0.660834  -1.928161   3.544945   \n",
            "\n",
            "   Feature_6  Feature_7  Feature_8  Feature_9  Target  \n",
            "0   1.332551   1.578256   2.124722  -0.318434       0  \n",
            "1  -1.794192   2.346422   1.700778  -0.001190       1  \n",
            "2  -0.755951   1.331933   2.041105  -0.824404       0  \n",
            "3  -0.915477  -3.184768  -0.399260  -3.920960       0  \n",
            "4   1.446944  -1.111662   0.313766  -2.376528       0  \n",
            "\n",
            "===================================\n",
            " Model: Decision Tree\n",
            "===================================\n",
            "Accuracy: 0.8566666666666667\n",
            "\n",
            "Confusion Matrix:\n",
            "[[136  26]\n",
            " [ 17 121]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.84      0.86       162\n",
            "           1       0.82      0.88      0.85       138\n",
            "\n",
            "    accuracy                           0.86       300\n",
            "   macro avg       0.86      0.86      0.86       300\n",
            "weighted avg       0.86      0.86      0.86       300\n",
            "\n",
            "\n",
            "===================================\n",
            " Model: Bagging\n",
            "===================================\n",
            "Accuracy: 0.8733333333333333\n",
            "\n",
            "Confusion Matrix:\n",
            "[[137  25]\n",
            " [ 13 125]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.85      0.88       162\n",
            "           1       0.83      0.91      0.87       138\n",
            "\n",
            "    accuracy                           0.87       300\n",
            "   macro avg       0.87      0.88      0.87       300\n",
            "weighted avg       0.88      0.87      0.87       300\n",
            "\n",
            "\n",
            "===================================\n",
            " Model: Boosting (AdaBoost)\n",
            "===================================\n",
            "Accuracy: 0.8\n",
            "\n",
            "Confusion Matrix:\n",
            "[[113  49]\n",
            " [ 11 127]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.70      0.79       162\n",
            "           1       0.72      0.92      0.81       138\n",
            "\n",
            "    accuracy                           0.80       300\n",
            "   macro avg       0.82      0.81      0.80       300\n",
            "weighted avg       0.82      0.80      0.80       300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn matplotlib\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 1. Sample text documents\n",
        "# --------------------------------------------------------------\n",
        "documents = [\n",
        "    \"Artificial intelligence is transforming the world.\",\n",
        "    \"Machine learning is a subset of artificial intelligence.\",\n",
        "    \"Deep learning uses neural networks.\",\n",
        "    \"Neural networks train on large datasets.\",\n",
        "    \"The cat sits on the mat.\",\n",
        "    \"Cats and dogs are common household pets.\",\n",
        "    \"Dogs enjoy playing fetch with their owners.\",\n",
        "    \"Pets like cats and dogs are loved by families.\"\n",
        "]\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 2. Convert documents to TF-IDF vectors\n",
        "# --------------------------------------------------------------\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 3. Perform K-means clustering\n",
        "# --------------------------------------------------------------\n",
        "k = 2  # number of clusters\n",
        "kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "labels = kmeans.fit_predict(X)\n",
        "\n",
        "print(\"\\n===== DOCUMENT CLUSTERS =====\")\n",
        "for i, label in enumerate(labels):\n",
        "    print(f\"Cluster {label}: {documents[i]}\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 4. Similarity Recognition Example\n",
        "# --------------------------------------------------------------\n",
        "query = [\"AI and machine learning are closely related.\"]\n",
        "\n",
        "query_vec = vectorizer.transform(query)\n",
        "similarities = cosine_similarity(query_vec, X).flatten()\n",
        "\n",
        "print(\"\\n===== SIMILARITY SCORES WITH QUERY =====\")\n",
        "for i, score in enumerate(similarities):\n",
        "    print(f\"{score:.4f}  -->  {documents[i]}\")\n",
        "\n",
        "best_match = np.argmax(similarities)\n",
        "\n",
        "print(\"\\nMost similar document:\")\n",
        "print(documents[best_match])\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 5. PCA for Visualization (2D graph)\n",
        "# --------------------------------------------------------------\n",
        "pca = PCA(n_components=2)\n",
        "X_2d = pca.fit_transform(X.toarray())\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot each document\n",
        "for i in range(len(X_2d)):\n",
        "    plt.scatter(X_2d[i, 0], X_2d[i, 1],\n",
        "                c='red' if labels[i] == 0 else 'blue', s=70)\n",
        "    plt.text(X_2d[i, 0] + 0.01, X_2d[i, 1] + 0.01, str(i), fontsize=9)\n",
        "\n",
        "plt.title(\"K-Means Clustering Visualized with PCA\")\n",
        "plt.xlabel(\"PCA Component 1\")\n",
        "plt.ylabel(\"PCA Component 2\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6kyRwTkxb0mO",
        "outputId": "f20e61e0-59b9-45b5-8236-32fb84ff0c0b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "\n",
            "===== DOCUMENT CLUSTERS =====\n",
            "Cluster 1: Artificial intelligence is transforming the world.\n",
            "Cluster 0: Machine learning is a subset of artificial intelligence.\n",
            "Cluster 0: Deep learning uses neural networks.\n",
            "Cluster 0: Neural networks train on large datasets.\n",
            "Cluster 1: The cat sits on the mat.\n",
            "Cluster 1: Cats and dogs are common household pets.\n",
            "Cluster 1: Dogs enjoy playing fetch with their owners.\n",
            "Cluster 1: Pets like cats and dogs are loved by families.\n",
            "\n",
            "===== SIMILARITY SCORES WITH QUERY =====\n",
            "0.0000  -->  Artificial intelligence is transforming the world.\n",
            "0.6438  -->  Machine learning is a subset of artificial intelligence.\n",
            "0.2656  -->  Deep learning uses neural networks.\n",
            "0.0000  -->  Neural networks train on large datasets.\n",
            "0.0000  -->  The cat sits on the mat.\n",
            "0.0000  -->  Cats and dogs are common household pets.\n",
            "0.0000  -->  Dogs enjoy playing fetch with their owners.\n",
            "0.0000  -->  Pets like cats and dogs are loved by families.\n",
            "\n",
            "Most similar document:\n",
            "Machine learning is a subset of artificial intelligence.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1kAAAIjCAYAAADxz9EgAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYvxJREFUeJzt3Xl4FFX+/v27sxOSEBAIWyQSZEfgAYmBLyCyBGUQEGWVTUREFhV0gFFZVMQFHVwijiggKuCACAxqJGyyL7KoIKuKjGDYIQlh6STn+aN/6SEkgW6oTujk/bquvqROnar+VJ8Cc6eqTtuMMUYAAAAAAEv4FHQBAAAAAFCYELIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgCgiOrXr5+ioqIKuozrcvDgQdlsNs2cObOgS7mqVatWyWazadWqVTddHQUx/p4eN3eOqV+/fgoJCfFIHQBAyAJw05s5c6ZsNpt++OGHbO1nz55V48aNFRQUpISEhKtua7PZtHbt2hzrjTGKjIyUzWbT3/72N4/Un9+Sk5M1YcIE1atXTyEhISpWrJjq1KmjUaNG6ciRI/lWx/vvv3/ThyB3DR8+XDabTQcOHMizz3PPPSebzaaffvopHytDbtLS0jR+/HiPhNy7777b+W+LzWZTqVKldOedd2r69OnKzMzM0X/VqlV64IEHVK5cOQUEBKhs2bLq0KGDFixYkOv+d+/eLZvNpqCgIJ05c8by+gF4FiELgFdKTk5W27Zt9dNPP+mrr75Su3btrto/KChIs2fPztH+/fff688//1RgYKCnSs1Xv/32m+rXr6+XXnpJtWrV0muvvaZ33nlHLVu21Mcff6y7774732rxZMiqXLmyzp8/r969e3tk/3np1auXJOV6LmWZM2eO6tatqzvuuEPNmzfX+fPn1bx58/wq0WXTpk3T3r17C7oMS115TGlpaZowYYLHriRWqlRJn376qT799FO98MILSk9P14ABA/SPf/wjW79x48apZcuW2rlzpwYNGqQPPvhAzz77rFJTU9WlS5dcz6fPPvtM5cqVkyTNnz/fI/UD8By/gi4AANyVkpKiuLg47dixQwsWLNC99957zW3uu+8+zZs3T++88478/P73T9/s2bPVsGFDnThxwpMl54v09HQ98MADOnr0qFatWqX/+7//y7Z+4sSJeu211wqoOmukp6crMzNTAQEBCgoKyvf3j4mJUdWqVTVnzhyNHTs2x/oNGzbo999/16uvvipJ8vHxKZA6XeHv71/QJVguv4+pRIkSevjhh53LgwYNUvXq1fXee+/ppZdekr+/v+bPn68XX3xRDz74oGbPnp2txmeffVbfffed7HZ7tv0aYzR79mz17NlTv//+uz7//HM9+uij+XZcAG4cV7IAeJXU1FS1a9dO27Zt05dffqn27du7tF2PHj108uRJJSYmOtsuXbqk+fPnq2fPnrluk5mZqSlTpqh27doKCgpSRESEBg0apNOnT2frt2jRIrVv314VKlRQYGCgoqOj9dJLLykjIyNbv7vvvlt16tTRL7/8opYtWyo4OFgVK1bU66+/nuO93333XdWuXVvBwcEqWbKkGjVqdNWrJ5L05Zdf6scff9Rzzz2XI2BJUlhYmCZOnJjn9nk9P5TbczRJSUnq37+/KlWqpMDAQJUvX14dO3bUwYMHJUlRUVHatWuXvv/+e+ftVJdfRTtz5oyeeuopRUZGKjAwUFWrVtVrr72W7TarrPedPHmypkyZoujoaAUGBuqXX37JtaasZ2wOHz6sTp06KSQkRGXKlNEzzzyTYyxOnjyp3r17KywsTOHh4erbt69+/PFHl54X6tWrl/bs2aNt27blWDd79mzZbDb16NEjz890//796tKli8qVK6egoCBVqlRJ3bt319mzZ/P8vLPYbDaNHz/eufzHH3/oiSeeUPXq1VWsWDHdcssteuihh5zjcDVXPr905e1vl78ur8WVscvq169fP5UoUcL5Gbty29uZM2fk6+urd955x9l24sQJ+fj46JZbbpExxtk+ePBg59WeK4/p4MGDKlOmjCRpwoQJzmO5/POT5NL54qrg4GDdddddOnfunI4fPy5JeuGFF1SqVClNnz491xAYFxeX41bldevW6eDBg+revbu6d++u1atX688//7yumgAUDK5kAfAa586d07333qstW7Zo/vz5bj1DFRUVpdjYWM2ZM8d55evbb7/V2bNn1b1792w/0GUZNGiQZs6cqf79+2v48OH6/fff9d5772n79u1at26d8wemmTNnKiQkRCNGjFBISIhWrFihsWPHKjk5WW+88Ua2fZ4+fVrt2rXTAw88oK5du2r+/PkaNWqU6tat66xr2rRpGj58uB588EE9+eSTunDhgn766Sdt2rQpz0AoSYsXL5akfLmFrkuXLtq1a5eGDRumqKgoHTt2TImJiTp06JCioqI0ZcoUDRs2TCEhIXruueckSREREZIct3C1aNFChw8f1qBBg3Trrbdq/fr1GjNmjP766y9NmTIl23vNmDFDFy5c0GOPPabAwECVKlUq12deJCkjI0NxcXGKiYnR5MmTtWzZMr355puKjo7W4MGDJTnCc4cOHbR582YNHjxYNWrU0KJFi9S3b1+Xjr1Xr16aMGGCZs+erf/v//v/sr33v//9bzVr1ky33nprrtteunRJcXFxunjxooYNG6Zy5crp8OHDWrJkic6cOaMSJUq4VEOWLVu2aP369erevbsqVaqkgwcPaurUqbr77rv1yy+/KDg42OV9Pffcczmulnz22Wf67rvvVLZsWUmuj50xRh07dtTatWv1+OOPq2bNmvrqq69c+ozDw8NVp04drV69WsOHD5ckrV27VjabTadOndIvv/yi2rVrS5LWrFmjZs2a5bqfMmXKaOrUqRo8eLA6d+6sBx54QJJ0xx13OPu4cr6467fffpOvr6/Cw8O1f/9+7dmzR4888ohCQ0Nd3sfnn3+u6Oho3XnnnapTp46Cg4M1Z84cPfvss9dVE4ACYADgJjdjxgwjyVSuXNn4+/ubhQsXur3tli1bzHvvvWdCQ0NNWlqaMcaYhx56yLRs2dIYY0zlypVN+/btndutWbPGSDKff/55tv0lJCTkaM/a3+UGDRpkgoODzYULF5xtLVq0MJLMrFmznG0XL1405cqVM126dHG2dezY0dSuXdvlY8zSoEEDU6JECZf79+3b11SuXNm5vHLlSiPJrFy5Mlu/33//3UgyM2bMMMYYc/r0aSPJvPHGG1fdf+3atU2LFi1ytL/00kumePHiZt++fdnaR48ebXx9fc2hQ4eyvW9YWJg5duzYVWvKOh5J5sUXX8zWt0GDBqZhw4bO5S+//NJIMlOmTHG2ZWRkmHvuuSfHPvNy5513mkqVKpmMjAxnW9a58a9//cvZduVnun37diPJzJs3L89953ZsWSSZcePGOZdzO/c2bNiQ4zzLbWyvHP8rrVu3zvj7+5tHHnnE2ebq2C1cuNBIMq+//rqzT3p6umnWrJlLn/GQIUNMRESEc3nEiBGmefPmpmzZsmbq1KnGGGNOnjxpbDabefvtt/M8puPHj+f4zC7v68r5kpcWLVqYGjVqmOPHj5vjx4+b3bt3m+HDhxtJpkOHDsYYYxYtWmQkmX/+85/X3F+WS5cumVtuucU899xzzraePXuaevXqubwPAAWP2wUBeI2jR48qKChIkZGR17V9165ddf78eS1ZskQpKSlasmRJnleG5s2bpxIlSqhNmzY6ceKE89WwYUOFhIRo5cqVzr7FihVz/jklJUUnTpxQs2bNlJaWpj179mTbb0hISLZnOAICAtS4cWP99ttvzrbw8HD9+eef2rJli1vHl5yc7NZvy69XsWLFFBAQoFWrVuW4ddIV8+bNU7NmzVSyZMlsn23r1q2VkZGh1atXZ+vfpUsX521frnj88cezLTdr1izb55uQkCB/f38NHDjQ2ebj46MhQ4a4/B4PP/yw/vzzz2y1zp49WwEBAXrooYfy3C7rStV3332ntLQ0l98vL5efe3a7XSdPnlTVqlUVHh6e6+2MrkpKStKDDz6o+vXr6/3333e2uzp233zzjfz8/LJdDfL19dWwYcNcev9mzZrp6NGjzkks1qxZo+bNm6tZs2Zas2aNJMfVLWNMnleyXHWt8+Vq9uzZozJlyqhMmTKqWbOm3n33XbVv317Tp0+X5Pg7Kcmtv5fffvutTp486bzlVHLc7vzjjz9q165dLu8HQMEiZAHwGv/6178UEBCgdu3aZZtBLCMjQ0lJSdlely5dyrF9mTJl1Lp1a82ePVsLFixQRkaGHnzwwVzfa//+/Tp79qzKli3r/CEq65Wamqpjx445++7atUudO3dWiRIlFBYWpjJlyjiDVNZzNlkqVaokm82Wra1kyZLZwsqoUaMUEhKixo0b6/bbb9eQIUO0bt26a34+YWFhSklJuWa/GxUYGKjXXntN3377rSIiItS8eXO9/vrrSkpKcmn7/fv3KyEhIcfn2rp1a0nK9tlK0m233eZybUFBQTkC2ZWf7x9//KHy5cvnuJWuatWqLr9P9+7d5evr63xO7sKFC/rqq6907733qmTJknlud9ttt2nEiBH66KOPVLp0acXFxSk+Pj7HeeKq8+fPa+zYsc7no0qXLq0yZcrozJkz173P9PR0de3aVRkZGVqwYEG2mTddHbusz/jK76GqXr26SzVkBac1a9bo3Llz2r59u5o1a6bmzZs7Q9aaNWsUFhamevXqXddxSq6dL1cTFRWlxMRELVu2TGvXrlVSUpKWLFmi0qVLS3L8nZTk1t/Lzz77TLfddpsCAwN14MABHThwQNHR0QoODtbnn3/u8n4AFCyeyQLgNWrVqqVvvvlGrVq1Ups2bbRu3TpFRkbqv//9b44fxFeuXJnrdOU9e/bUwIEDlZSUpHvvvVfh4eG5vldmZqbKli2b5w81WT+YnTlzRi1atFBYWJhefPFFRUdHKygoSNu2bdOoUaNyPDvk6+ub6/7MZQ/z16xZU3v37tWSJUuUkJCgL7/8Uu+//77Gjh2rCRMm5PXxqEaNGtq+fbv++9//XtfVvivDX5bcJgF46qmn1KFDBy1cuFDfffedXnjhBU2aNEkrVqxQgwYNrvo+mZmZatOmjf7+97/nur5atWrZli+/WnMteX2+VitbtqzatGmjL7/8UvHx8frPf/6jlJQU5xTvV/Pmm2+qX79+WrRokZYuXarhw4dr0qRJ2rhxY64hPEtu4zBs2DDNmDFDTz31lGJjY1WiRAnZbDZ17949z+fWruXZZ5/Vhg0btGzZMlWqVCnbOnfH7npVqFBBt912m1avXq2oqCgZYxQbG6syZcroySef1B9//KE1a9aoSZMm8vG5/t8X3+j5Urx4cWfAzE2NGjUkST///LNL+0tOTtZ//vMfXbhwQbfffnuO9bNnz9bEiRPzPEcA3DwIWQC8SuPGjbVw4UK1b99ebdq00Zo1a1SuXLlsswZKyvO32507d9agQYO0ceNGffHFF3m+T3R0tJYtW6amTZte9Yf8VatW6eTJk1qwYEG270L6/fff3Tyy7IoXL65u3bqpW7duunTpkh544AFNnDhRY8aMyXNK8A4dOmjOnDn67LPPNGbMGLffM+sKzJUzwP3xxx+59o+OjtbIkSM1cuRI7d+/X/Xr19ebb76pzz77TFLeoS06OlqpqalX/eHUkypXrqyVK1cqLS0t29Wsq33BcG569eqlhIQEffvtt5o9e7bCwsLUoUMHl7atW7eu6tatq+eff17r169X06ZN9cEHH+jll192axzmz5+vvn376s0333S2Xbhw4bq/vHbu3LmaMmWKpkyZohYtWuRY7+rYVa5cWcuXL1dqamq2q1nufC9Xs2bNtHr1at12222qX7++QkNDVa9ePZUoUUIJCQnatm3bVX/pIOV9DuaXatWqqXr16lq0aJHefvvtHFf2rrRgwQJduHBBU6dOdV4Ny7J37149//zzWrduXa6zhwK4uXC7IACv06pVK82ZM0cHDhxQu3btdOnSJbVu3TrbK69btkJCQjR16lSNHz/+qj8QZ90u9dJLL+VYl56e7vwhNus34Zdfibp06VK251jcdfLkyWzLAQEBqlWrlowxOb5P53IPPvig6tatq4kTJ2rDhg051qekpDhn+stN5cqV5evrm+OZqCuPJS0tTRcuXMjWFh0drdDQUF28eNHZVrx48Vx/2O/atas2bNig7777Lse6M2fOKD09Pc8arRAXFye73a5p06Y52zIzMxUfH+/Wfjp16qTg4GC9//77+vbbb/XAAw9c8zuxkpOTcxxf3bp15ePj4/zswsLCVLp06WuOg+Q4/y4/9yTH9P/XMwX5zp079eijj+rhhx/Wk08+mWsfV8fuvvvuU3p6uqZOnepcn5GRoXfffdflepo1a6aDBw/qiy++cN4+6OPjoyZNmuitt96S3W6/5vNYWSH6ekOnFSZMmKCTJ0/q0UcfzfXcXrp0qZYsWSLJcatglSpV9Pjjj+vBBx/M9nrmmWcUEhLCLYOAl+BKFgCv1LlzZ02bNk2PPPKI7r//fiUkJLj8pa+uTCPdokULDRo0SJMmTdKOHTvUtm1b+fv7a//+/Zo3b57efvttPfjgg2rSpIlKliypvn37avjw4bLZbPr0009z/ODrjrZt26pcuXJq2rSpIiIitHv3br333ntq3779VR+g9/f314IFC9S6dWs1b95cXbt2VdOmTeXv769du3Zp9uzZKlmyZJ7flVWiRAk99NBDevfdd2Wz2RQdHa0lS5bkeEZq3759atWqlbp27apatWrJz89PX331lY4eParu3bs7+zVs2FBTp07Vyy+/rKpVq6ps2bK655579Oyzz2rx4sX629/+pn79+qlhw4Y6d+6cfv75Z82fP18HDx7M8Vt8K3Xq1EmNGzfWyJEjdeDAAdWoUUOLFy/WqVOnJLl+9SMkJESdOnVyPpflyq2CK1as0NChQ/XQQw+pWrVqSk9P16effipfX1916dLF2e/RRx/Vq6++qkcffVSNGjXS6tWrtW/fvhz7+9vf/qZPP/1UJUqUUK1atZy3+d1yyy0uHcPl+vfvL0lq3ry582pkliZNmqhKlSouj12HDh3UtGlTjR49WgcPHlStWrW0YMECt54TywpQe/fu1SuvvOJsb968ub799lsFBgbqzjvvvOo+ihUrplq1aumLL75QtWrVVKpUKdWpU0d16tRxuY4b1a1bN/3888+aOHGitm/frh49eqhy5co6efKkEhIStHz5cs2ePVtHjhzRypUrndPWXykwMFBxcXHOL1UvjF8mDRQqBTizIQC45PJp2K80efJkI8n87W9/M3a73a1tL3flFO5ZPvzwQ9OwYUNTrFgxExoaaurWrWv+/ve/myNHjjj7rFu3ztx1112mWLFipkKFCubvf/+7+e6773JMmd2iRYtcp2a/ctrpf/3rX6Z58+bmlltuMYGBgSY6Oto8++yz5uzZs1c9hiynT582Y8eONXXr1jXBwcEmKCjI1KlTx4wZM8b89ddfeb6vMY4pr7t06WKCg4NNyZIlzaBBg8zOnTuzTbt94sQJM2TIEFOjRg1TvHhxU6JECRMTE2P+/e9/Z9tXUlKSad++vQkNDTWSsk3nnpKSYsaMGWOqVq1qAgICTOnSpU2TJk3M5MmTzaVLl4wx/5vKPLep4vOawr148eI5+o4bN85c+b+748ePm549e5rQ0FBTokQJ069fP7Nu3TojycydO9eVj9kYY8zXX39tJJny5ctnm849y5VTp//222/mkUceMdHR0SYoKMiUKlXKtGzZ0ixbtizbdmlpaWbAgAGmRIkSJjQ01HTt2tUcO3Ysx3Tkp0+fNv379zelS5c2ISEhJi4uzuzZs8dUrlzZ9O3bN886sj6vy8e/cuXKRlKur8s/Z1fGzhjHFOu9e/c2YWFhpkSJEqZ3797OKexdmSbfGGPKli1rJJmjR48629auXWskmWbNmuXon9s5vX79etOwYUMTEBCQ7fNz53zJTV5/n/OyfPly07FjR1O2bFnj5+dnypQpYzp06GAWLVpkjDHmzTffNJLM8uXL89zHzJkzjSTnNgBuXjZjbuDXrQAAFBILFy5U586dtXbtWjVt2rSgywEAeDFCFgCgyDl//ny2CU0yMjLUtm1b/fDDD0pKSnJrRkMAAK7EM1kAgCJn2LBhOn/+vGJjY3Xx4kUtWLBA69ev1yuvvELAAgDcMK5kAQCKnNmzZ+vNN9/UgQMHdOHCBVWtWlWDBw/W0KFDC7o0AEAhQMgCAAAAAAvxPVkAAAAAYCFCFgAAAABYiIkvriEzM1NHjhxRaGioy19QCQAAAKDwMcYoJSVFFSpUkI9P3terCFnXcOTIEUVGRhZ0GQAAAABuEv/9739VqVKlPNcTsq4hNDRUkuODDAsLK+BqvIPdbtfSpUvVtm1b+fv7F3Q5yGeMPzgHijbGH5wDRVthH//k5GRFRkY6M0JeCFnXkHWLYFhYGCHLRXa7XcHBwQoLCyuUf7lwdYw/OAeKNsYfnANFW1EZ/2s9RsTEFwAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJCFm5LdbtfQoUNVsmRJlSpVSsOGDVN6enpBlwUAAABcEyELN6WXX35Za9eu1S+//KJdu3ZpzZo1euWVVwq6LAAAAOCaCFm4KU2fPl3PP/+8ypcvr/Lly+u5557Txx9/XNBlAQAAANdEyMJN5/Tp0/rzzz9Vv359Z1v9+vV16NAhnT17tuAKAwAAAFxAyMJNJzU1VZIUHh7ubMv6c0pKSgFUBAAAALiOkIUCYUze60JCQiQp21WrrD+HhoZ6tC4AAADgRhGykC+MkTZulHr3lsLCJF9fx39793a0Xx66SpYsqUqVKmnHjh3Oth07digyMlIlSpTI/+IBAAAANxCy4HF2u9S/vxQbK82dK6WkOEJVSopjOTbWsd5u/982/fv318SJE5WUlKSkpCS98sorevTRRwvuIAAAAAAX+RV0ASjcjJEGDpRmzXIsX/lVV1nLWetnzJBsNumFF17QyZMnVbNmTUnSww8/rH/84x/5VDUAAABw/biSBY/atEn65JOrP4MlOdZ/8om0ebNj2d/fX/Hx8Tp9+rROnz6td999V35+/E4AAAAANz+vC1nx8fGKiopSUFCQYmJitDnrp/I8nDlzRkOGDFH58uUVGBioatWq6ZtvvsmnahEfL7majfz8HP0BAAAAb+ZVlwa++OILjRgxQh988IFiYmI0ZcoUxcXFae/evSpbtmyO/pcuXVKbNm1UtmxZzZ8/XxUrVtQff/yRbWpweNaiRTlvEcxLerq0cKFHywEAAAA8zqtC1ltvvaWBAweqf//+kqQPPvhAX3/9taZPn67Ro0fn6D99+nSdOnVK69evl7+/vyQpKioqP0su0oyR/t9XXrksNdWxnc3mmZoAAAAAT/OakHXp0iVt3bpVY8aMcbb5+PiodevW2rBhQ67bLF68WLGxsRoyZIgWLVqkMmXKqGfPnho1apR8fX1z3ebixYu6ePGiczk5OVmSZLfbZb98+jvkKetzSk+3q3Rp94JWSIjrV75wc8oaf/6+FF2cA0Ub4w/OgaKtsI+/q8flNSHrxIkTysjIUERERLb2iIgI7dmzJ9dtfvvtN61YsUK9evXSN998owMHDuiJJ56Q3W7XuHHjct1m0qRJmjBhQo72pUuXKjg4+MYPpAhJTEzUtGnub8cjc4VDYmJiQZeAAsY5ULQx/uAcKNoK6/inpaW51M9rQtb1yMzMVNmyZfXhhx/K19dXDRs21OHDh/XGG2/kGbLGjBmjESNGOJeTk5MVGRmptm3bKiwsLL9K92p2u12JiYlq06aNduzwV+vWrm+7fLnUqJHnaoPnXT7+WbfpomjhHCjaGH9wDhRthX38s+5yuxavCVmlS5eWr6+vjh49mq396NGjKleuXK7blC9fXv7+/tluDaxZs6aSkpJ06dIlBQQE5NgmMDBQgYGBOdr9/f0L5YniSf7+/oqN9VfXro7vwbraNO42m9Snj3TXXTyPVVjwdwacA0Ub4w/OgaKtsI6/q8fkNVO4BwQEqGHDhlq+fLmzLTMzU8uXL1dsbGyu2zRt2lQHDhxQZmams23fvn0qX758rgEL1rPZpGnTHAFKyjmde9Zynz6OfgQsAAAAeDuvCVmSNGLECE2bNk2ffPKJdu/ercGDB+vcuXPO2Qb79OmTbWKMwYMH69SpU3ryySe1b98+ff3113rllVc0ZMiQgjqEIsnfX5oxQ9q4UerRQwoNdYSp0FDH8saNjvWF8JcdAAAAKIK85nZBSerWrZuOHz+usWPHKikpSfXr11dCQoJzMoxDhw7Jx+d/uTEyMlLfffednn76ad1xxx2qWLGinnzySY0aNaqgDqHIstmkmBjHS2KadgAAABReXhWyJGno0KEaOnRorutWrVqVoy02NlYbN270cFVwFwELAAAAhZVX3S4IAAAAADc7QhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZhcx7772nRo0aKTAwUJ06dSrocgAAAIAix6+gC4C1KlSooOeff17Lli3Tn3/+WdDlAAAAAEUOIauQeeCBByRJO3bsIGQBAAAABYDbBQEAAADAQoQsAAAAALAQIcvbGFPQFQAAAAC4CkLWzc4YaeNGqXdvKSxM8vV1/Ld3b0c7oQsAAAC4qRCybmZ2u9S/vxQbK82dK6WkOEJVSopjOTbWsd5ud26Snp6uCxcuKD09XZmZmbpw4YIuXbpUgAcBAAAAFC3MLnizMkYaOFCaNcuxnJ6efX3Wctb6GTMkm00vv/yyJkyY4OxWrFgxtWjRQqtWrfJ8zQAAAAC4knXT2rRJ+uSTa98OaIyj3+bNkqTx48fLGJPtRcACAAAA8g8h62YVHy/5uXih0c/P0R8AAABAgSNk3awWLcp5i2Be0tOlhQs9Wg4AAAAA1xCybkbGSKmp7m2TmspMgwAAAMBNgJB1M7LZpJAQ97YJCXFsBwAAAKBAEbJuVh07uvdMVqdOHi0HAAAAgGsIWTerIUPceyZryBDP1gMAAADAJYSsm1VMjNS377VvAbTZHP0aN86fugAAAABcFSHrZmWzSdOmSX36OJavvHUwa7lPH0c/nscCAAAAbgqErJuZv780Y4a0caPUo4cUGuoIU6GhjuWNGx3r/f0LulIAAAAA/4+LMyugwNhsjlsHY2Icy8Zw1QoAAAC4iXEly9sQsAAAAICbGiELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEJeF7Li4+MVFRWloKAgxcTEaPPmzS5tN3fuXNlsNnXq1MmzBQIAAAAo0rwqZH3xxRcaMWKExo0bp23btqlevXqKi4vTsWPHrrrdwYMH9cwzz6hZs2b5VCkAAACAosqrQtZbb72lgQMHqn///qpVq5Y++OADBQcHa/r06Xluk5GRoV69emnChAmqUqVKPlYLAAAAoCjyK+gCXHXp0iVt3bpVY8aMcbb5+PiodevW2rBhQ57bvfjiiypbtqwGDBigNWvWXPN9Ll68qIsXLzqXk5OTJUl2u112u/0GjqDoyPqc+LyKJsYfnANFG+MPzoGirbCPv6vH5TUh68SJE8rIyFBERES29oiICO3ZsyfXbdauXauPP/5YO3bscPl9Jk2apAkTJuRoX7p0qYKDg92quahLTEws6BJQgBh/cA4UbYw/OAeKtsI6/mlpaS7185qQ5a6UlBT17t1b06ZNU+nSpV3ebsyYMRoxYoRzOTk5WZGRkWrbtq3CwsI8UWqhY7fblZiYqDZt2sjf37+gy0E+Y/zBOVC0Mf7gHCjaCvv4Z93ldi1eE7JKly4tX19fHT16NFv70aNHVa5cuRz9f/31Vx08eFAdOnRwtmVmZkqS/Pz8tHfvXkVHR+fYLjAwUIGBgTna/f39C+WJ4kl8ZkUb4w/OgaKN8QfnQNFWWMff1WPymokvAgIC1LBhQy1fvtzZlpmZqeXLlys2NjZH/xo1aujnn3/Wjh07nK/7779fLVu21I4dOxQZGZmf5QMAAAAoIrzmSpYkjRgxQn379lWjRo3UuHFjTZkyRefOnVP//v0lSX369FHFihU1adIkBQUFqU6dOtm2Dw8Pl6Qc7QAAAABgFa8KWd26ddPx48c1duxYJSUlqX79+kpISHBOhnHo0CH5+HjNxTkAAAAAhZBXhSxJGjp0qIYOHZrrulWrVl1125kzZ1pfEAAAAABchss+AAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFvC5kxcfHKyoqSkFBQYqJidHmzZvz7Dtt2jQ1a9ZMJUuWVMmSJdW6deur9gcAAACAG+VVIeuLL77QiBEjNG7cOG3btk316tVTXFycjh07lmv/VatWqUePHlq5cqU2bNigyMhItW3bVocPH87nygEAAAAUFV4Vst566y0NHDhQ/fv3V61atfTBBx8oODhY06dPz7X/559/rieeeEL169dXjRo19NFHHykzM1PLly/P58oBAAAAFBV+BV2Aqy5duqStW7dqzJgxzjYfHx+1bt1aGzZscGkfaWlpstvtKlWqVJ59Ll68qIsXLzqXk5OTJUl2u112u/06qy9asj4nPq+iifEH50DRxviDc6BoK+zj7+pxeU3IOnHihDIyMhQREZGtPSIiQnv27HFpH6NGjVKFChXUunXrPPtMmjRJEyZMyNG+dOlSBQcHu1d0EZeYmFjQJaAAMf7gHCjaGH9wDhRthXX809LSXOrnNSHrRr366quaO3euVq1apaCgoDz7jRkzRiNGjHAuJycnO5/lCgsLy49SvZ7dbldiYqLatGkjf3//gi4H+YzxB+dA0cb4g3OgaCvs4591l9u1eE3IKl26tHx9fXX06NFs7UePHlW5cuWuuu3kyZP16quvatmyZbrjjjuu2jcwMFCBgYE52v39/QvlieJJfGZFG+MPzoGijfEH50DRVljH39Vj8pqJLwICAtSwYcNsk1ZkTWIRGxub53avv/66XnrpJSUkJKhRo0b5USoAAACAIsxrrmRJ0ogRI9S3b181atRIjRs31pQpU3Tu3Dn1799fktSnTx9VrFhRkyZNkiS99tprGjt2rGbPnq2oqCglJSVJkkJCQhQSElJgxwEAAACg8PKqkNWtWzcdP35cY8eOVVJSkurXr6+EhATnZBiHDh2Sj8//Ls5NnTpVly5d0oMPPphtP+PGjdP48ePzs3QAAAAARYRXhSxJGjp0qIYOHZrrulWrVmVbPnjwoOcLAgAAAIDLeM0zWQAAAADgDQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIbdC1vnz57V27Vr98ssvOdZduHBBs2bNsqwwAAAAAPBGLoesffv2qWbNmmrevLnq1q2rFi1a6K+//nKuP3v2rPr37++RIgEAAADAW7gcskaNGqU6dero2LFj2rt3r0JDQ9W0aVMdOnTIk/UBAAAAgFdxOWStX79ekyZNUunSpVW1alX95z//UVxcnJo1a6bffvvNkzUCAAAAgNdwOWSdP39efn5+zmWbzaapU6eqQ4cOatGihfbt2+eRAgEAAADAm/hdu4tDjRo19MMPP6hmzZrZ2t977z1J0v33329tZQAAAADghVy+ktW5c2fNmTMn13XvvfeeevToIWOMZYUBAAAAgDdyOWSNGTNG33zzTZ7r33//fWVmZlpSFAAAAAB4K76MGAAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALCQ2yFr9erVSk9Pz9Genp6u1atXW1IUAAAAAHgrt0NWy5YtderUqRztZ8+eVcuWLS0pCgAAAAC8ldshyxgjm82Wo/3kyZMqXry4JUUBAAAAgLfyc7XjAw88IEmy2Wzq16+fAgMDnesyMjL0008/qUmTJtZXCAAAAABexOWQVaJECUmOK1mhoaEqVqyYc11AQIDuuusuDRw40PoKAQAAAMCLuByyZsyYIUmKiorSM888w62BAAAAAJALl0NWlnHjxnmiDgAAAAAoFNye+OLo0aPq3bu3KlSoID8/P/n6+mZ7AQAAAEBR5vaVrH79+unQoUN64YUXVL58+VxnGgQAAACAosrtkLV27VqtWbNG9evX90A5AAAAAODd3L5dMDIyUsYYT9QCAAAAAF7P7ZA1ZcoUjR49WgcPHvRAOQAAAADg3dy+XbBbt25KS0tTdHS0goOD5e/vn239qVOnLCsOAAAAALyN2yFrypQpHigDAAAAAFwTEhLi/PPFixeVnp4um82m4OBgSVJiYqJiY2MLqjz3Q1bfvn09UQcAAAAAuCQ1NdX55379+mnJkiUaMWKE/vGPfxRgVf/j9jNZkvTrr7/q+eefV48ePXTs2DFJ0rfffqtdu3ZZWhwAAAAAXM3x48d16tQp9evXr6BLcXI7ZH3//feqW7euNm3apAULFjhT5I8//qhx48ZZXiAAAAAA5OXAgQPy8/NTnTp1VLt2bb355pvKzMws0JrcDlmjR4/Wyy+/rMTERAUEBDjb77nnHm3cuNHS4gAAAAAgL+fOndPhw4f10Ucf6fjx4/r444/19ttv6+233y7QutwOWT///LM6d+6co71s2bI6ceKEJUUBAAAAKNou/2revL6md968eQoNDVXPnj3l6+uru+66S6NHj9YXX3yRP0Xmwe2QFR4err/++itH+/bt21WxYkVLigIAAABQtBgjbdwo9e4thYVJvr6Sv7/j5eMjhYY61m3c+L/Q9dFHH6lv377y8/vffH4+Ptc17YSl3K6ge/fuGjVqlJKSkmSz2ZSZmal169bpmWeeUZ8+fTxRIwAAAIBCzG6X+veXYmOluXOllBRHkEpPd7wkKTVVmjPH0ad/f2nnzr1av369ypcvr+TkZBlj9MMPP+jVV19Vly5dCvR43A5Zr7zyimrUqKHIyEilpqaqVq1aat68uZo0aaLnn3/eEzUCAAAAKKSMkQYOlGbNcixnharcZGQ4/jtrltS9+8dq1qyZvvzyS916660KDQ1Vr1699MQTT2jkyJGeL/wq3P6erICAAE2bNk0vvPCCdu7cqdTUVDVo0EC33367J+oDAAAAUIht2iR98ol72xgj7dr1ujZulGJiPFPXjXA7ZGW59dZbdeutt1pZCwAAAIAiJj5e8vO7+hWs3Pj5ObYtFCErIyNDM2fO1PLly3Xs2LEcc9CvWLHCsuIAAAAAFG6LFrkfsCTHNgsXWl6OJdwOWU8++aRmzpyp9u3bq06dOrLZbJ6oCwAAAEAhZ4xjQovrlZrq2MfNFkncDllz587Vv//9b913332eqAcAAABAEWGzSSEhjtkEr0dIyM0XsKTrmF0wICBAVatW9UQtAAAAhcrixYtVv359FS9eXBUqVNAHH3xQ0CUBN52OHR3PV7nLz0/q1MnycizhdsgaOXKk3n77bZm8vnYZAAAASkhI0BNPPKEpU6YoOTlZu3bt0t13313QZQE3nSFDrv+ZrCFDrK/HCm5nxrVr12rlypX69ttvVbt2bfn7+2dbv2DBAsuKAwAA8FYvvPCCxo4d6wxWJUuWVMmSJQu2KOAmFBMj9e3r+O4rV6/j2GxSnz5S48aere16uR2ywsPD1blzZ0/UAgAAUCicO3dOW7du1X333adq1aopOTlZzZo10zvvvKPy5csXdHnATcVmk6ZNc/z5k0+uPp27r6/jC4n79HFsczM+jyVdR8iaMWOGJ+oAAAAoNE6fPi1jjBYuXKjExETdcsstevzxx/Xwww9r+fLlBV0ecNPx95dmzJAGD3Z899XChY6ZA319HevT0x2TXHTu7LhFsHHjmzdgSTfwZcTHjx/X3r17JUnVq1dXmTJlLCsKAADgZne1aaNDQkIkScOHD1flypUlSRMmTNDtt9+uc+fOqXjx4vlVJuA1bDbHrYNZXy58+d+xm3Ga9qtxe+KLc+fO6ZFHHlH58uXVvHlzNW/eXBUqVNCAAQOUlpbmiRoBAAAKnDHSxo1S795SWJjjN+xhYY7ljRuzP0sSHh6uW2+9NY/9MHkY4IrLQ5U3BSzpOkLWiBEj9P333+s///mPzpw5ozNnzmjRokX6/vvvNXLkSE/UCAAAUKDsdql/fyk2Vpo71/GdPsY4/jt3rqO9f39HvyyPPfaY3n33XR0+fFjnz5/Xiy++qFatWjmvcgEovNy+XfDLL7/U/Pnzs01Bet9996lYsWLq2rWrpk6damV9AAAABcoYaeBAx8xnUs4H8rOWs9bPmOH4rfvo0aN16tQp1atXT5LUsmVLffrpp/lUNYCC5PaVrLS0NEVERORoL1u2LLcLAgCAQmfTJseMZ9e6y88YR7/Nmx3Lvr6+evPNN3XixAmdOHFC8+bNU7ly5TxfMIAC53bIio2N1bhx43ThwgVn2/nz5zVhwgTFxsZaWhwAAEBBi493TCntCj8/R38ARZvbIevtt9/WunXrVKlSJbVq1UqtWrVSZGSk1q9fr7ffftsTNWYTHx+vqKgoBQUFKSYmRpuzfl2Uh3nz5qlGjRoKCgpS3bp19c0333i8RgAAUHgsWpT3d/ZcKT3dMfU0gKLN7ZBVp04d7d+/X5MmTVL9+vVVv359vfrqq9q/f79q167tiRqdvvjiC40YMULjxo3Ttm3bVK9ePcXFxenYsWO59l+/fr169OihAQMGaPv27erUqZM6deqknTt3erROAABQOBjj+K4ed6SmXvvWQgCF23V9T1ZwcLAGDhxodS3X9NZbb2ngwIHq37+/JOmDDz7Q119/renTp2v06NE5+r/99ttq166dnn32WUnSSy+9pMTERL333nv64IMP8rV2AADgfWw2xxegpqS4vk1IiPdNNw3AWtcVsvbu3at3331Xu3fvliTVrFlTQ4cOVY0aNSwt7nKXLl3S1q1bNWbMGGebj4+PWrdurQ0bNuS6zYYNGzRixIhsbXFxcVp4lev4Fy9e1MWLF53LycnJkiS73S775fOyIk9ZnxOfV9HE+INzoGgrjOPfpYv05Zeu3TLo5yc9+GD2qdyLmsJ4DsB1hX38XT2u65rCvXv37mrUqJFzoouNGzeqbt26mjt3rrp06eLuLl1y4sQJZWRk5JjZMCIiQnv27Ml1m6SkpFz7JyUl5fk+kyZN0oQJE3K0L126VMHBwddRedGVmJhY0CWgADH+RcvFixf15JNPKjk5WbNnz5bEOVDUFabx79TJ8XIHj4AXrnMA7ius4+/qbOpuh6y///3vGjNmjF588cVs7ePGjdPf//53j4Ws/DJmzJhsV7+Sk5MVGRmptm3bKiwsrAAr8x52u12JiYlq06aN/P39C7oc5DPGv2gaPXq0atasqW3btqlNmzacA0VYYfw3wBjpiSekOXOu/qyVzSb16CG9/37Rvl2wMJ4DcF1hH/+su9yuxe2Q9ddff6lPnz452h9++GG98cYb7u7OZaVLl5avr6+OHj2arf3o0aN5fudEuXLl3OovSYGBgQoMDMzR7u/vXyhPFE/iMyvaGP+iY+vWrVq6dKnefPNNde3a1TnunANFW2Eb/6lTHbcLfvKJ45bAy28dzFru29fRrxAd9g0pbOcA3FNYx9/VY3J7dsG7775ba9asydG+du1aNWvWzN3duSwgIEANGzbU8uXLnW2ZmZlavnx5nt/PFRsbm62/5Lh0yfd5AYA10tPTNXDgQMXHxysgIKCgywE8xt9fmjFD2rjRcbUqNNRxtSo01LG8caNjfSH8mRLAdXD7Stb999+vUaNGaevWrbrrrrskOZ7JmjdvniZMmKDFixdn62ulESNGqG/fvmrUqJEaN26sKVOm6Ny5c87ZBvv06aOKFStq0qRJkqQnn3xSLVq00Jtvvqn27dtr7ty5+uGHH/Thhx9aWhcAFFVvvPGGGjRooObNm2vVqlUFXQ7gUTabFBPjeEmOWweL8m2BAPLmdsh64oknJEnvv/++3n///VzXSZLNZlNGRsYNlpddt27ddPz4cY0dO1ZJSUmqX7++EhISnJNbHDp0SD4+/7s416RJE82ePVvPP/+8/vGPf+j222/XwoULVadOHUvrAoDC6mo/RB44cEAffPCBtm/fnr9FATcJAhaAvLgdsjIzMz1Rh8uGDh2qoUOH5rout9+iPvTQQ3rooYc8XBUAFA7GSJs2SfHx0qJFji9VDQmROnaUhgxx/AY/6wfLtWvX6ujRo6pWrZokx8POKSkpKl++vEaNGqX77ruvAI8EAICC4/YzWQCAwslul/r3l2JjpblzHV++aozjv3PnOtr79//f9/907dpVBw4c0I4dO7Rjxw599NFHCg0N1ZYtW3TbbbcV7MEAAFCAruvLiLds2aKVK1fq2LFjOa5svfXWW5YUBgDIP8ZIAwdKs2Y5lq/80tWs5az1M2ZIwcHB2b4/sEyZMrLZbKpUqZJ++umnfKgaAICbk9sh65VXXtHzzz+v6tWrKyIiQrbLbki2cXMyAHilTZscU1NfizGOfoMH/+/h/yx33323zpw5I3vWpS4AAIoot0PW22+/renTp6tfv34eKAcAUBDi43N+909e/Pwc/a8MWQAAwMHtZ7J8fHzUtGlTT9QCACggixa5FrAkR7+FCz1aDgAAXs3tkPX0008rPj7eE7UAAAqAMY5ZBN2RmurYDgAA5OT27YLPPPOM2rdvr+joaNWqVUv+V3y1+YIFCywrDgDgeTabY5r2lBTXtwkJ4TuCAADIi9tXsoYPH66VK1eqWrVquuWWW1SiRIlsLwCA9+nY0fGslSv8/KROnTxaDgAAXs3tK1mffPKJvvzyS7Vv394T9QAACsCQIdJnn7nWNz3d0R8AAOTO7StZpUqVUnR0tCdqAQAUkJgYqW/fa98CaLM5+jVunD91AQDgjdwOWePHj9e4ceOUlpbmiXoAAAXAZpOmTZP69HEsX3nrYNZynz6OfjyPBQBA3ty+XfCdd97Rr7/+qoiICEVFReWY+GLbtm2WFQcAyD/+/tKMGY4vGo6Pd0zTnprqmOSiUyfHLYKNGxOwAAC4FrdDVieedgaAQstmc9w6mPVFw8YQqgAAcJfbIWvcuHGeqAMAcBMiYAEA4D63Q1aWrVu3avfu3ZKk2rVrq0GDBpYVBQAAAADeyu2QdezYMXXv3l2rVq1SeHi4JOnMmTNq2bKl5s6dqzJlylhdIwAAAAB4DbdnFxw2bJhSUlK0a9cunTp1SqdOndLOnTuVnJys4cOHe6JGAAAAAPAabl/JSkhI0LJly1SzZk1nW61atRQfH6+2bdtaWhwAAAAAeBu3r2RlZmbmmLZdkvz9/ZWZmWlJUQAAAADgrdwOWffcc4+efPJJHTlyxNl2+PBhPf3002rVqpWlxQEAAACAt3E7ZL333ntKTk5WVFSUoqOjFR0drdtuu03Jycl69913PVEjAAAAAHgNt5/JioyM1LZt27Rs2TLt2bNHklSzZk21bt3a8uIAAAAAwNtc1/dk2Ww2tWnTRm3atLG6HgAAAADwai7fLrhixQrVqlVLycnJOdadPXtWtWvX1po1aywtDgAAAAC8jcsha8qUKRo4cKDCwsJyrCtRooQGDRqkt956y9LiAAAAAMDbuByyfvzxR7Vr1y7P9W3bttXWrVstKQoAAAAAvJXLIevo0aO5fj9WFj8/Px0/ftySogAAAADAW7kcsipWrKidO3fmuf6nn35S+fLlLSkKAAAAALyVyyHrvvvu0wsvvKALFy7kWHf+/HmNGzdOf/vb3ywtDgAAAAC8jctTuD///PNasGCBqlWrpqFDh6p69eqSpD179ig+Pl4ZGRl67rnnPFYoAAAAAHgDl0NWRESE1q9fr8GDB2vMmDEyxkhyfGdWXFyc4uPjFRER4bFCAQAAAMAbuPVlxJUrV9Y333yj06dP68CBAzLG6Pbbb1fJkiU9VR8AAAAAeBW3QlaWkiVL6s4777S6FgAAAADwei5PfAEAAAAAuDZCFgAAAABYiJAFAAAAABayLGRlZmZqyZIlVu0OAAAAALzSdU18cbkDBw5o+vTpmjlzpo4fPy673W5FXQAAAADgla7rStb58+c1a9YsNW/eXNWrV9f69es1duxY/fnnn1bXBwAAAABexa0rWVu2bNFHH32kuXPnKjo6Wr169dL69ev1/vvvq1atWp6qEQAAAAC8hssh64477lBycrJ69uyp9evXq3bt2pKk0aNHe6w4AAAAAPA2Lt8uuHfvXjVv3lwtW7bkqhUAAAAA5MHlkPXbb7+pevXqGjx4sCpVqqRnnnlG27dvl81m82R9AAAAAOBVXA5ZFStW1HPPPacDBw7o008/VVJSkpo2bar09HTNnDlT+/bt82SdAAAAAOAVrmt2wXvuuUefffaZ/vrrL7333ntasWKFatSooTvuuMPq+gAAAADAq9zQlxGXKFFCTzzxhH744Qdt27ZNd999t0VlAQAAAIB3cjlknT9/XosXL1ZKSkqOdcnJyTp06JDeeOMNS4sDAAAAAG/jcsj68MMP9fbbbys0NDTHurCwML3zzjv66KOPLC0OAAAAALyNyyHr888/11NPPZXn+qeeekqffPKJFTUBAAAAgNdyOWTt379f9erVy3P9HXfcof3791tSFAAAAAB4K5dDVnp6uo4fP57n+uPHjys9Pd2SogAAAADAW7kcsmrXrq1ly5bluX7p0qWqXbu2JUUBAAAAgLdyOWQ98sgjeumll7RkyZIc6/7zn/9o4sSJeuSRRywtDgAAAAC8jZ+rHR977DGtXr1a999/v2rUqKHq1atLkvbs2aN9+/apa9eueuyxxzxWKAAAAAB4A7e+jPizzz7T3Llzdfvtt2vfvn3au3evqlevrjlz5mjOnDmeqhEAAAAAvIbLV7KydO3aVV27dvVELQAAAADg9Vy+kpWZmanXXntNTZs21Z133qnRo0fr/Pnznqwtm1OnTqlXr14KCwtTeHi4BgwYoNTU1Kv2HzZsmKpXr65ixYrp1ltv1fDhw3X27Nl8qxkAAABA0eNyyJo4caL+8Y9/KCQkRBUrVtTbb7+tIUOGeLK2bHr16qVdu3YpMTFRS5Ys0erVq6/6DNiRI0d05MgRTZ48WTt37tTMmTOVkJCgAQMG5FvNAAAAAIoel28XnDVrlt5//30NGjRIkrRs2TK1b99eH330kXx83Hq0y227d+9WQkKCtmzZokaNGkmS3n33Xd13332aPHmyKlSokGObOnXq6Msvv3QuR0dHa+LEiXr44YeVnp4uPz+375QEAAAAgGtyOWkcOnRI9913n3O5devWstlsOnLkiCpVquSR4rJs2LBB4eHhzoCV9f4+Pj7atGmTOnfu7NJ+zp49q7CwsKsGrIsXL+rixYvO5eTkZEmS3W6X3W6/ziMoWrI+Jz6voonxB+dA0cb4g3OgaCvs4+/qcbkcstLT0xUUFJStzd/fP18+wKSkJJUtWzZbm5+fn0qVKqWkpCSX9nHixAm99NJL15xmftKkSZowYUKO9qVLlyo4ONj1oqHExMSCLgEFiPEH50DRxviDc6BoK6zjn5aW5lI/l0OWMUb9+vVTYGCgs+3ChQt6/PHHVbx4cWfbggULXC5y9OjReu21167aZ/fu3S7vLy/Jyclq3769atWqpfHjx1+175gxYzRixIhs20ZGRqpt27YKCwu74VqKArvdrsTERLVp00b+/v4FXQ7yGeMPzoGijfEH50DRVtjHP+sut2txOWT17ds3R9vDDz/sekW5GDlypPr163fVPlWqVFG5cuV07NixbO3p6ek6deqUypUrd9XtU1JS1K5dO4WGhuqrr7665mAHBgZmC5JZ/P39C+WJ4kl8ZkUb4w/OgaKN8QfnQNFWWMff1WNyOWTNmDHjuovJS5kyZVSmTJlr9ouNjdWZM2e0detWNWzYUJK0YsUKZWZmKiYmJs/tkpOTFRcXp8DAQC1evDjH7Y4AAAAAYDXPTgtokZo1a6pdu3YaOHCgNm/erHXr1mno0KHq3r27c2bBw4cPq0aNGtq8ebMkR8Bq27atzp07p48//ljJyclKSkpSUlKSMjIyCvJwAAAAABRiXjOP+eeff66hQ4eqVatW8vHxUZcuXfTOO+8419vtdu3du9f5MNq2bdu0adMmSVLVqlWz7ev3339XVFRUvtUOAAAAoOjwmpBVqlQpzZ49O8/1UVFRMsY4l+++++5sywAAAACQH7zidkEAAAAA8BaELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQl4Tsk6dOqVevXopLCxM4eHhGjBggFJTU13a1hije++9VzabTQsXLvRsoQAAAACKNK8JWb169dKuXbuUmJioJUuWaPXq1Xrsscdc2nbKlCmy2WwerhAAAAAAJL+CLsAVu3fvVkJCgrZs2aJGjRpJkt59913dd999mjx5sipUqJDntjt27NCbb76pH374QeXLl7/me128eFEXL150LicnJ0uS7Ha77Hb7DR5J0ZD1OfF5FU2MPzgHijbGH5wDRVthH39Xj8srQtaGDRsUHh7uDFiS1Lp1a/n4+GjTpk3q3LlzrtulpaWpZ8+eio+PV7ly5Vx6r0mTJmnChAk52pcuXarg4ODrO4AiKjExsaBLQAFi/ME5ULQx/uAcKNoK6/inpaW51M8rQlZSUpLKli2brc3Pz0+lSpVSUlJSnts9/fTTatKkiTp27Ojye40ZM0YjRoxwLicnJysyMlJt27ZVWFiY+8UXQXa7XYmJiWrTpo38/f0LuhzkM8YfnANFG+MPzoGirbCPf9ZdbtdSoCFr9OjReu21167aZ/fu3de178WLF2vFihXavn27W9sFBgYqMDAwR7u/v3+hPFE8ic+saGP8wTlQtDH+4Bwo2grr+Lt6TAUaskaOHKl+/fpdtU+VKlVUrlw5HTt2LFt7enq6Tp06ledtgCtWrNCvv/6q8PDwbO1dunRRs2bNtGrVqhuoHAAAAAByV6Ahq0yZMipTpsw1+8XGxurMmTPaunWrGjZsKMkRojIzMxUTE5PrNqNHj9ajjz6ara1u3br65z//qQ4dOtx48QAAAACQC694JqtmzZpq166dBg4cqA8++EB2u11Dhw5V9+7dnTMLHj58WK1atdKsWbPUuHFjlStXLterXLfeeqtuu+22/D4EAAAAAEWE13xP1ueff64aNWqoVatWuu+++/R///d/+vDDD53r7Xa79u7d6/KMHwAAAADgCV5xJUuSSpUqpdmzZ+e5PioqSsaYq+7jWusBAAAA4EZ5zZUsAAAAAPAGhCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQs3nYsXL2rgwIG67bbbFBoaqho1amj69OkFXRYAAADgEr+CLgC4Unp6usqXL69ly5apSpUq2rRpk+69915VqlRJbdu2LejyAAAAgKviShZuOsWLF9eLL76o6Oho2Ww23XXXXWrZsqXWrl1b0KUBAAAA10TIwk3vwoUL2rx5s+64446CLgUAAAC4JkIWbmrGGD366KO6/fbb9cADDxR0OQAAAMA18UwW8p8xks3mQjejJ554Qnv37tWyZcvk48PvBAAAAHDz46dWeJ4x0saNUu/eUliY5Ovr+G/v3o52Y3LZxGjIkCHatGmTli5dqhIlShRA4QAAAID7CFnwLLtd6t9fio2V5s6VUlIcoSolxbEcG+tYb7dn22zo0KFat26dEhMTVbJkyQIqHgAAAHAfIQueY4w0cKA0a5ZjOT09+/qs5VmzHP3+3xWtP/74Q++//7727t2rypUrKyQkRCEhIXr88cfzsXgAAADg+vBMFjznhx+kTz65dj9jHP0GD5ZiYlS5cmWZXG4hBAAAALwBV7LgOdOmSX4u5ng/Pyk+3rP1AAAAAPmAkAXP+frrnLcI5iU9XVq40KPlAAAAAPmBkAXPOXfOvf6pqbnONAgAAAB4E0IWPKd4cff6h4S49P1ZAAAAwM2MkAXPad/evWeyOnXyaDkAAABAfiBkwXMGDnTvmawhQzxbDwAAAJAPCFnwnEaNpL59r30LoM3m6Ne4cf7UBQAAAHgQIQueY7M5pnHv08exfOWtg1nLffo4+vE8FgAAAAoBQhY8y99fmjFD2rhR6tFDCg11hKnQUMfyxo2O9f7+BV0pAAAAYAkXZyUAboDNJsXEOF6SY5p2rloBAACgkOJKFvIfAQsAAACFGCELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAs5DUh69SpU+rVq5fCwsIUHh6uAQMGKDU19ZrbbdiwQffcc4+KFy+usLAwNW/eXOfPn8+HigEAAAAURV4Tsnr16qVdu3YpMTFRS5Ys0erVq/XYY49ddZsNGzaoXbt2atu2rTZv3qwtW7Zo6NCh8vHxmsMGAAAA4GX8CroAV+zevVsJCQnasmWLGjVqJEl69913dd9992ny5MmqUKFCrts9/fTTGj58uEaPHu1sq169+lXf6+LFi7p48aJzOTk5WZJkt9tlt9tv9FCKhKzPic+raGL8wTlQtDH+4Bwo2gr7+Lt6XDZjjPFwLTds+vTpGjlypE6fPu1sS09PV1BQkObNm6fOnTvn2ObYsWOKiIjQO++8ozlz5ujXX39VjRo1NHHiRP3f//1fnu81fvx4TZgwIUf77NmzFRwcbM0BAQAAAPA6aWlp6tmzp86ePauwsLA8+3nFlaykpCSVLVs2W5ufn59KlSqlpKSkXLf57bffJDlC0+TJk1W/fn3NmjVLrVq10s6dO3X77bfnut2YMWM0YsQI53JycrIiIyPVtm3bq36Q+B+73a7ExES1adNG/v7+BV0O8hnjD86Boo3xB+dA0VbYxz/rLrdrKdCQNXr0aL322mtX7bN79+7r2ndmZqYkadCgQerfv78kqUGDBlq+fLmmT5+uSZMm5bpdYGCgAgMDc7T7+/sXyhPFk/jMijbGH5wDRRvjD86Boq2wjr+rx1SgIWvkyJHq16/fVftUqVJF5cqV07Fjx7K1p6en69SpUypXrlyu25UvX16SVKtWrWztNWvW1KFDh66/aAAAAAC4igINWWXKlFGZMmWu2S82NlZnzpzR1q1b1bBhQ0nSihUrlJmZqZiYmFy3iYqKUoUKFbR3795s7fv27dO9995748UDHjJs2DAtXLhQZ8+eVWhoqB566CG9/vrrCggIKOjSAAAA4AKvmMu8Zs2aateunQYOHKjNmzdr3bp1Gjp0qLp37+6cWfDw4cOqUaOGNm/eLEmy2Wx69tln9c4772j+/Pk6cOCAXnjhBe3Zs0cDBgwoyMMBruqJJ57Qnj17lJycrB9//FE//vijXn/99YIuCwAAAC7yiokvJOnzzz/X0KFD1apVK/n4+KhLly565513nOvtdrv27t2rtLQ0Z9tTTz2lCxcu6Omnn9apU6dUr149JSYmKjo6uiAOAXBJzZo1nX82xsjHx0f79+8vwIoAAADgDq8JWaVKldLs2bPzXB8VFaXcZqMfPXp0tu/JArzBq6++qpdfflnnzp3TLbfccs0JYgAAAHDz8IrbBYGiZvTo0UpNTdUvv/yixx9/PM8JXgAAAHDzIWQB+c2N7/+uWbOm6tWrd81ZOAEAAHDzIGQBnmaMtHGj1Lu3FBYm+fo6/tu7t6P9GqHLbrfzTBYAAIAXIWQBnmS3S/37S7Gx0ty5UkqKI1SlpDiWY2Md6+12SVJqaqpmzJihM2fOyBijn3/+WS+//LLi4uIK+EAAAADgKkIW4CnGSAMHSrNmOZbT07Ovz1qeNcvRzxjZbDbNnj1b0dHRCg0NVceOHdW+fXtNmTIlX0sHAADA9fOa2QUBr7Npk/TJJ9fuZ4yj3+DBKh4To8TERM/XBgAAAI/hShbgKfHxkp+Lv8fw83P0BwAAgNcjZAGesmhRzlsE85KeLi1c6NFyAAAAkD8IWYAnGCOlprq3TWqqW9O7AwAA4OZEyAI8wWaTQkLc2yYkxLEdAAAAvBohC/CUjh3deyarUyePlgMAAID8QcgCPGXIEPeeyRoyxLP1AAAAIF8QsgBPiYmR+va99i2ANpujX+PG+VMXAAAAPIqQBXiKzSZNmyb16eNYvvLWwazlPn0c/XgeCwAAoFAgZAGe5O8vzZghbdwo9eghhYY6wlRoqGN540bHen//gq4UAAAAFnHxqXwA181mc9w6GBPjWDaGq1YAAACFGFeygPxGwAIAACjUCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFvIr6AJudsYYSVJycnIBV+I97Ha70tLSlJycLH9//4IuB/mM8QfnQNHG+INzoGgr7OOflQmyMkJeCFnXkJKSIkmKjIws4EoAAAAA3AxSUlJUokSJPNfbzLViWBGXmZmpI0eOKDQ0VDabraDL8QrJycmKjIzUf//7X4WFhRV0OchnjD84B4o2xh+cA0VbYR9/Y4xSUlJUoUIF+fjk/eQVV7KuwcfHR5UqVSroMrxSWFhYofzLBdcw/uAcKNoYf3AOFG2FefyvdgUrCxNfAAAAAICFCFkAAAAAYCFCFiwXGBiocePGKTAwsKBLQQFg/ME5ULQx/uAcKNoYfwcmvgAAAAAAC3ElCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQs37NSpU+rVq5fCwsIUHh6uAQMGKDU11aVtjTG69957ZbPZtHDhQs8WCo9x9xw4deqUhg0bpurVq6tYsWK69dZbNXz4cJ09ezYfq8aNiI+PV1RUlIKCghQTE6PNmzdftf+8efNUo0YNBQUFqW7duvrmm2/yqVJ4gjvjP23aNDVr1kwlS5ZUyZIl1bp162ueL7j5uftvQJa5c+fKZrOpU6dOni0QHuXu+J85c0ZDhgxR+fLlFRgYqGrVqhX6/w8QsnDDevXqpV27dikxMVFLlizR6tWr9dhjj7m07ZQpU2Sz2TxcITzN3XPgyJEjOnLkiCZPnqydO3dq5syZSkhI0IABA/KxalyvL774QiNGjNC4ceO0bds21atXT3FxcTp27Fiu/devX68ePXpowIAB2r59uzp16qROnTpp586d+Vw5rODu+K9atUo9evTQypUrtWHDBkVGRqpt27Y6fPhwPlcOq7h7DmQ5ePCgnnnmGTVr1iyfKoUnuDv+ly5dUps2bXTw4EHNnz9fe/fu1bRp01SxYsV8rjyfGeAG/PLLL0aS2bJli7Pt22+/NTabzRw+fPiq227fvt1UrFjR/PXXX0aS+eqrrzxcLTzhRs6By/373/82AQEBxm63e6JMWKhx48ZmyJAhzuWMjAxToUIFM2nSpFz7d+3a1bRv3z5bW0xMjBk0aJBH64RnuDv+V0pPTzehoaHmk08+8VSJ8LDrOQfS09NNkyZNzEcffWT69u1rOnbsmA+VwhPcHf+pU6eaKlWqmEuXLuVXiTcFrmThhmzYsEHh4eFq1KiRs61169by8fHRpk2b8twuLS1NPXv2VHx8vMqVK5cfpcJDrvccuNLZs2cVFhYmPz8/T5QJi1y6dElbt25V69atnW0+Pj5q3bq1NmzYkOs2GzZsyNZfkuLi4vLsj5vX9Yz/ldLS0mS321WqVClPlQkPut5z4MUXX1TZsmW5Y8HLXc/4L168WLGxsRoyZIgiIiJUp04dvfLKK8rIyMivsgsEP83ghiQlJals2bLZ2vz8/FSqVCklJSXlud3TTz+tJk2aqGPHjp4uER52vefA5U6cOKGXXnrJ5dtMUXBOnDihjIwMRUREZGuPiIjQnj17ct0mKSkp1/6unh+4eVzP+F9p1KhRqlChQo7gDe9wPefA2rVr9fHHH2vHjh35UCE86XrG/7ffftOKFSvUq1cvffPNNzpw4ICeeOIJ2e12jRs3Lj/KLhBcyUKuRo8eLZvNdtWXq/9DvdLixYu1YsUKTZkyxdqiYSlPngOXS05OVvv27VWrVi2NHz/+xgsHcNN69dVXNXfuXH311VcKCgoq6HKQD1JSUtS7d29NmzZNpUuXLuhyUAAyMzNVtmxZffjhh2rYsKG6deum5557Th988EFBl+ZRXMlCrkaOHKl+/fpdtU+VKlVUrly5HA86pqen69SpU3neBrhixQr9+uuvCg8Pz9bepUsXNWvWTKtWrbqBymEVT54DWVJSUtSuXTuFhobqq6++kr+//42WDQ8rXbq0fH19dfTo0WztR48ezXO8y5Ur51Z/3LyuZ/yzTJ48Wa+++qqWLVumO+64w5NlwoPcPQd+/fVXHTx4UB06dHC2ZWZmSnLc9bB3715FR0d7tmhY5nr+DShfvrz8/f3l6+vrbKtZs6aSkpJ06dIlBQQEeLTmgsKVLOSqTJkyqlGjxlVfAQEBio2N1ZkzZ7R161bntitWrFBmZqZiYmJy3ffo0aP1008/aceOHc6XJP3zn//UjBkz8uPw4AJPngOS4wpW27ZtFRAQoMWLF/NbbS8REBCghg0bavny5c62zMxMLV++XLGxsbluExsbm62/JCUmJubZHzev6xl/SXr99df10ksvKSEhIdvzm/A+7p4DNWrU0M8//5zt//n333+/WrZsqR07digyMjI/y8cNup5/A5o2baoDBw44w7Uk7du3T+XLly+0AUsSswvixrVr1840aNDAbNq0yaxdu9bcfvvtpkePHs71f/75p6levbrZtGlTnvsQswt6NXfPgbNnz5qYmBhTt25dc+DAAfPXX385X+np6QV1GHDR3LlzTWBgoJk5c6b55ZdfzGOPPWbCw8NNUlKSMcaY3r17m9GjRzv7r1u3zvj5+ZnJkyeb3bt3m3Hjxhl/f3/z888/F9Qh4Aa4O/6vvvqqCQgIMPPnz8/2dz0lJaWgDgE3yN1z4ErMLujd3B3/Q4cOmdDQUDN06FCzd+9es2TJElO2bFnz8ssvF9Qh5AtCFm7YyZMnTY8ePUxISIgJCwsz/fv3z/Y/z99//91IMitXrsxzH4Qs7+buObBy5UojKdfX77//XjAHAbe8++675tZbbzUBAQGmcePGZuPGjc51LVq0MH379s3W/9///repVq2aCQgIMLVr1zZff/11PlcMK7kz/pUrV8717/q4cePyv3BYxt1/Ay5HyPJ+7o7/+vXrTUxMjAkMDDRVqlQxEydOLPS/VLUZY0wBXEADAAAAgEKJZ7IAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAIBb+vXrJ5vNJpvNpoCAAFWtWlUvvvii0tPTnX2MMfrwww8VExOjkJAQhYeHq1GjRpoyZYrS0tKy7e/PP/9UQECA6tSp43INSUlJGjZsmKpUqaLAwEBFRkaqQ4cOWr58uWXHWRj069dPnTp1uma/1atXq0OHDqpQoYJsNpsWLlzo8doAoDAjZAEA3NauXTv99ddf2r9/v0aOHKnx48frjTfecK7v3bu3nnrqKXXs2FErV67Ujh079MILL2jRokVaunRptn3NnDlTXbt2VXJysjZt2nTN9z548KAaNmyoFStW6I033tDPP/+shIQEtWzZUkOGDLH8WIuCc+fOqV69eoqPjy/oUgCgcDAAALihb9++pmPHjtna2rRpY+666y5jjDFffPGFkWQWLlyYY9vMzExz5syZbMtVqlQxCQkJZtSoUWbgwIHXfP97773XVKxY0aSmpuZYd/r0aeef//jjD3P//feb4sWLm9DQUPPQQw+ZpKQk5/px48aZevXqmY8//thERkaa4sWLm8GDB5v09HTz2muvmYiICFOmTBnz8ssvZ3sPSeb999837dq1M0FBQea2224z8+bNy9bnp59+Mi1btjRBQUGmVKlSZuDAgSYlJSXHZ/jGG2+YcuXKmVKlSpknnnjCXLp0ydnnwoULZuTIkaZChQomODjYNG7c2KxcudK5fsaMGaZEiRImISHB1KhRwxQvXtzExcWZI0eOOI9PUrbX5dvnRZL56quvrtkPAJA3rmQBAG5YsWLFdOnSJUnS559/rurVq6tjx445+tlsNpUoUcK5vHLlSqWlpal169Z6+OGHNXfuXJ07dy7P9zl16pQSEhI0ZMgQFS9ePMf68PBwSVJmZqY6duyoU6dO6fvvv1diYqJ+++03devWLVv/X3/9Vd9++60SEhI0Z84cffzxx2rfvr3+/PNPff/993rttdf0/PPP57jC9sILL6hLly768ccf1atXL3Xv3l27d++W5LgqFBcXp5IlS2rLli2aN2+eli1bpqFDh2bbx8qVK/Xrr79q5cqV+uSTTzRz5kzNnDnTuX7o0KHasGGD5s6dq59++kkPPfSQ2rVrp/379zv7pKWlafLkyfr000+1evVqHTp0SM8884wk6ZlnnlHXrl2dVx3/+usvNWnSJM/PFgBgoYJOeQAA73L5lazMzEyTmJhoAgMDzTPPPGOMMaZmzZrm/vvvd2lfPXv2NE899ZRzuV69embGjBl59t+0aZORZBYsWHDV/S5dutT4+vqaQ4cOOdt27dplJJnNmzcbYxxXeoKDg01ycrKzT1xcnImKijIZGRnOturVq5tJkyY5lyWZxx9/PNv7xcTEmMGDBxtjjPnwww9NyZIls11p+/rrr42Pj4/zSlrfvn1N5cqVTXp6urPPQw89ZLp162aMcVyF8/X1NYcPH872Pq1atTJjxowxxjiuZEkyBw4ccK6Pj483ERERzuXcrjpei7iSBQA3zK9AEx4AwCstWbJEISEhstvtyszMVM+ePTV+/HhJjkkvXHHmzBktWLBAa9eudbY9/PDD+vjjj9WvX79ct3F137t371ZkZKQiIyOdbbVq1VJ4eLh2796tO++8U5IUFRWl0NBQZ5+IiAj5+vrKx8cnW9uxY8ey7T82NjbH8o4dO5zvXa9evWxX2po2barMzEzt3btXERERkqTatWvL19fX2ad8+fL6+eefJUk///yzMjIyVK1atWzvc/HiRd1yyy3O5eDgYEVHR2fbx5W1AgDyHyELAOC2li1baurUqQoICFCFChXk5/e//51Uq1ZNe/bsueY+Zs+erQsXLigmJsbZZoxRZmam9u3blyNgSNLtt98um83m0v5d4e/vn23ZZrPl2paZmWnJ+13rvbPeJzU1Vb6+vtq6dWu2ICZJISEhV92Hq0EUAOA5PJMFAHBb8eLFVbVqVd16663ZApYk9ezZU/v27dOiRYtybGeM0dmzZyVJH3/8sUaOHKkdO3Y4Xz/++KOaNWum6dOn5/q+pUqVUlxcnOLj43N9duvMmTOSpJo1a+q///2v/vvf/zrX/fLLLzpz5oxq1ap1vYfttHHjxhzLNWvWdL73jz/+mK2+devWycfHR9WrV3dp/w0aNFBGRoaOHTumqlWrZnuVK1fO5ToDAgKUkZHhcn8AgDUIWQAAS3Xt2lXdunVTjx499Morr+iHH37QH3/8oSVLlqh169bOKd23bdumRx99VHXq1Mn26tGjhz755JNs37t1ufj4eGVkZKhx48b68ssvtX//fu3evVvvvPOO8za+1q1bq27duurVq5e2bdumzZs3q0+fPmrRooUaNWp0w8c4b948TZ8+Xfv27dO4ceO0efNm58QWvXr1UlBQkPr27audO3dq5cqVGjZsmHr37u28VfBaqlWrpl69eqlPnz5asGCBfv/9d23evFmTJk3S119/7XKdUVFR+umnn7R3716dOHFCdrs9136pqanOoCtJv//+u3bs2KFDhw65/F4AgP8hZAEALGWz2TR79my99dZbWrhwoVq0aKE77rhD48ePV8eOHRUXF6ePP/5YtWrVUo0aNXJs37lzZx07dkzffPNNrvuvUqWKtm3bppYtW2rkyJGqU6eO2rRpo+XLl2vq1KnOGhYtWqSSJUuqefPmat26tapUqaIvvvjCkmOcMGGC5s6dqzvuuEOzZs3SnDlznFfIgoOD9d133+nUqVO688479eCDD6pVq1Z677333HqPGTNmqE+fPho5cqSqV6+uTp06acuWLbr11ltd3sfAgQNVvXp1NWrUSGXKlNG6dety7ffDDz+oQYMGatCggSRpxIgRatCggcaOHetWzQAAB5vh5m0AAFxms9n01VdfqVOnTgVdCgDgJsWVLAAAAACwECELAAAAACzEFO4AALiBu+wBANfClSwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEL/PzcY9BuBsxTCAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}